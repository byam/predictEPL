{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from unidecode import unidecode\n",
    "import codecs\n",
    "import collections\n",
    "\n",
    "import sentiment_aware as sa\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "short_pos = codecs.open(\"short_reviews/positive1.txt\", encoding='utf-8').read()\n",
    "short_neg = codecs.open(\"short_reviews/negative1.txt\", encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Positive Reviews:  5332\n",
      "Short Negative Reviews:  5332\n"
     ]
    }
   ],
   "source": [
    "# create labeled documents\n",
    "documents = []\n",
    "\n",
    "for r in short_pos.split('\\n'):\n",
    "    documents.append( (r, \"pos\") )\n",
    "\n",
    "short_pos_len = len(documents)\n",
    "\n",
    "for r in short_neg.split('\\n'):\n",
    "    documents.append( (r, \"neg\") )\n",
    "\n",
    "short_neg_len = len(documents) - short_pos_len\n",
    "\n",
    "print \"Short Positive Reviews: \", short_pos_len\n",
    "print \"Short Negative Reviews: \", short_neg_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Sentiment Tokenizer Class as tok\n",
    "tok = sa.Tokenizer(preserve_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All words number:  225005\n"
     ]
    }
   ],
   "source": [
    "# create all words lists\n",
    "all_words = []\n",
    "\n",
    "short_pos_words = tok.tokenize(short_pos)\n",
    "short_neg_words = tok.tokenize(short_neg)\n",
    "\n",
    "for w in short_pos_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "for w in short_neg_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "print \"All words number: \", len(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get most frequent 5000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All unique words:  20679\n"
     ]
    }
   ],
   "source": [
    "print \"All unique words: \", len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_word_features = open(\"pickled_algos/word_features5k_shortReviews.pickle\",\"wb\")\n",
    "pickle.dump(word_features, save_word_features)\n",
    "save_word_features.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = tok.tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle all sets\n",
    "random.shuffle(featuresets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  8000\n",
      "Testing data:  2664\n"
     ]
    }
   ],
   "source": [
    "training_set = featuresets[:8000]\n",
    "testing_set =  featuresets[8000:]\n",
    "\n",
    "print \"Training data: \", len(training_set)\n",
    "print \"Testing data: \", len(testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Original Naive Bayes algo accuracy percent:', 65.27777777777779)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Naive Bayes algo accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                mediocre = True              neg : pos    =     13.5 : 1.0\n",
      "                   waste = True              neg : pos    =     11.5 : 1.0\n",
      "                 winning = True              pos : neg    =     11.1 : 1.0\n",
      "                delicate = True              pos : neg    =     10.5 : 1.0\n",
      "             mesmerizing = True              pos : neg    =      9.1 : 1.0\n",
      "              irritating = True              neg : pos    =      8.9 : 1.0\n",
      "                mindless = True              neg : pos    =      8.9 : 1.0\n",
      "                plotting = True              neg : pos    =      8.2 : 1.0\n",
      "             pretentious = True              neg : pos    =      8.0 : 1.0\n",
      "                  unique = True              pos : neg    =      7.9 : 1.0\n",
      "                    loud = True              neg : pos    =      7.7 : 1.0\n",
      "                 assured = True              pos : neg    =      7.1 : 1.0\n",
      "             moviemaking = True              pos : neg    =      7.1 : 1.0\n",
      "                  nicely = True              pos : neg    =      7.1 : 1.0\n",
      "                dazzling = True              pos : neg    =      7.1 : 1.0\n",
      "                 iranian = True              pos : neg    =      7.1 : 1.0\n",
      "                    chan = True              neg : pos    =      6.9 : 1.0\n",
      "                   fatal = True              neg : pos    =      6.9 : 1.0\n",
      "                disaster = True              neg : pos    =      6.9 : 1.0\n",
      "                  gentle = True              pos : neg    =      6.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo of Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Review: \n",
      "it may not be as cutting , as witty or as true as back in the glory days of weekend and two or three things i know about her , but who else engaged in filmmaking today is so cognizant of the cultural and moral issues involved in the process ? \n",
      "Result of Naive Bayes Classifier: \n",
      "pos\n",
      "\n",
      "Negative Review: \n",
      "it should be mentioned that the set design and interiors of the haunted vessel are more than effectively creepy and moodily lit . so i just did . \n",
      "Result of Naive Bayes Classifier: \n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "example_pos = short_pos.split('\\n')[random.randint(0, len(short_pos.split('\\n')) - 1)]\n",
    "example_neg = short_neg.split('\\n')[random.randint(0, len(short_neg.split('\\n')) - 1)]\n",
    "\n",
    "print \"Positive Review: \\n\", example_pos\n",
    "print \"Result of Naive Bayes Classifier: \\n\", classifier.classify(find_features(example_pos))\n",
    "\n",
    "print \"\\nNegative Review: \\n\", example_neg\n",
    "print \"Result of Naive Bayes Classifier: \\n\", classifier.classify(find_features(example_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_classifier = open(\"pickled_algos/naiveBayes_for_short_reviews.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using save Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saved_classifier_f = open(\"pickled_algos/naiveBayes_for_short_reviews.pickle\", \"rb\")\n",
    "saved_classifier = pickle.load(saved_classifier_f)\n",
    "saved_classifier_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Saved Classifier accuracy percent:', 65.27777777777779)\n"
     ]
    }
   ],
   "source": [
    "print(\"Saved Classifier accuracy percent:\",(nltk.classify.accuracy(saved_classifier, testing_set))*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

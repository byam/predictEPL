{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/Bya/git/predictEPL/MyFunctions/')\n",
    "import tokenizers\n",
    "import senti_word_net\n",
    "import featx\n",
    "import replacers\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pickle\n",
    "with open('/Users/Bya/nltk_data/taggers/treebank_aubt.pickle', 'rb') as f:\n",
    "    tagger_aubt = pickle.load(f)\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"/Users/Bya/git/predictEPL/NLTK/NLTK_TUTORIAL/pickled_algos/naiveBayes_for_short_reviews_NEW.pickle\", \"rb\") as saved_classifier_f:\n",
    "    nb_classifier = pickle.load(saved_classifier_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| WordNet tag        | Treebank tag| Word |\n",
    "|-------------:| -----:|\n",
    "| n      | NN | Noun |\n",
    "| a      | JJ      |  Adjective | \n",
    "| r|RB | Adverb |\n",
    "| v|VB | Verb |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = [\n",
    "\"Great start to the evening seeing Mo Farah win the 5000m, now for #Arsenal. #Beijing2015 #NEWARS http://t.co/9ulMYqQ91M\",\n",
    "\"Good squad there. Could be in with a very small chance #nufc\",\n",
    "\"Blog: Newcastle United feedback: Will the Magpies replace like for like if they sell? http://t.co/rxfXZbGwVE #NUFC\",\n",
    "\"FourFourTwo: Knee injury sidelines Ozil http://t.co/rxfXZbGwVE #NUFC\",\n",
    "\"Blog: Newcastle United coach Steve Black has got in spot on once again http://t.co/rxfXZbGwVE #NUFC\",\n",
    "\"RT @ghanafans: KICK OFF - #Arsenal will be attacking from right to left #NUFCvAFC  #BPL\",\n",
    "\"I hate that andre marraner he is a total cock #nufc\",\n",
    "\"Really dirty stuff from Sissoko, stomping on Nacho Monreal's ankle. Only a yellow but could have been a sending off. #Arsenal #NUFC\",\n",
    "\"Really please to make my debut for this fantastic club. Great to get the win. Now we focus on Saturdays game #toonarmy #NUFC\",\n",
    "\"RT @TheSunFootball: #Arsenal break well through Sanchez and Oxlade-Chamberlain. Terrible return pass from Ramsey wrecks the move. 0-0\",\n",
    "\"RT @NUFC_Index: NUFC hunting in packs early on!\",\n",
    "\"Gets a yellow for a stamp!#nufc\",\n",
    "\"Come on gunners! #NUFCvAFC #Arsenal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1=====================================================\n",
      "\n",
      "Tweet: \n",
      " \n",
      " Great start to the evening seeing Mo Farah win the 5000m, now for #Arsenal. #Beijing2015 #NEWARS http://t.co/9ulMYqQ91M \n",
      "\n",
      "Words(tweetTokenizer): \n",
      "\n",
      " ['Great', 'start', 'to', 'the', 'evening', 'seeing', 'Mo', 'Farah', 'win', 'the', '5000m', ',', 'now', 'for', '#Arsenal', '.', '#Beijing2015', '#NEWARS', 'http://t.co/9ulMYqQ91M'] \n",
      "\n",
      "Words(byaCleaner): \n",
      " \n",
      " ['great', 'start', 'evening', 'seeing', 'mo', 'farah', 'win', '5000m', 'http'] \n",
      "\n",
      "\n",
      "---------------Naive Bayes--------------------------------------\n",
      "\n",
      "Naive Bayes Sentiment: pos\n",
      "\t pos: 0.8784748393924136\n",
      "\t neg: 0.12152516060758803\n",
      "\n",
      "---------------SentiWordNet--------------------------------------\n",
      "\n",
      "POS tags: \n",
      "\n",
      " [('great', 'JJ'), ('start', 'VB'), ('evening', 'NN'), ('seeing', 'VBG'), ('mo', 'NN'), ('farah', 'NNP'), ('win', 'VB'), ('5000m', 'NN'), ('http', 'NN')] \n",
      "\n",
      "\n",
      "WordNet tags: \n",
      "\n",
      " [('great', 'a'), ('start', 'v'), ('evening', 'n'), ('seeing', 'v'), ('mo', 'n'), ('farah', 'n'), ('win', 'v'), ('5000m', 'n'), ('http', 'n')] \n",
      "\n",
      "\n",
      "SentiWordNet-Word: \n",
      "\n",
      " [('great', (0.0, 0.0, 0.0)), ('start', (0.008928571428571428, 0.026785714285714284, 0.9642857142857143)), ('evening', (0.0, 0.0, 1.0)), ('seeing', (0.046875, 0.005208333333333333, 0.9479166666666666)), ('mo', (0.0, 0.0, 1.0)), ('farah', (0.0, 0.0, 0.0)), ('win', (0.15625, 0.0, 0.84375)), ('5000m', (0.0, 0.0, 0.0)), ('http', (0.0, 0.0, 1.0))] \n",
      "\n",
      "\n",
      "SentiWordNet-Tweet: pos \n",
      " \t\t pos: 0.21205357142857142 \n",
      " \t\t neg: 0.031994047619047616 \n",
      " \t\t obj: 2.755952380952381 \n",
      "\n",
      "Example 2=====================================================\n",
      "\n",
      "Tweet: \n",
      " \n",
      " Good squad there. Could be in with a very small chance #nufc \n",
      "\n",
      "Words(tweetTokenizer): \n",
      "\n",
      " ['Good', 'squad', 'there', '.', 'Could', 'be', 'in', 'with', 'a', 'very', 'small', 'chance', '#nufc'] \n",
      "\n",
      "Words(byaCleaner): \n",
      " \n",
      " ['good', 'squad', 'could', 'small', 'chance'] \n",
      "\n",
      "\n",
      "---------------Naive Bayes--------------------------------------\n",
      "\n",
      "Naive Bayes Sentiment: pos\n",
      "\t pos: 0.8286439927706086\n",
      "\t neg: 0.17135600722939348\n",
      "\n",
      "---------------SentiWordNet--------------------------------------\n",
      "\n",
      "POS tags: \n",
      "\n",
      " [('good', 'JJ'), ('squad', 'NN'), ('could', 'MD'), ('small', 'JJ'), ('chance', 'NN')] \n",
      "\n",
      "\n",
      "WordNet tags: \n",
      "\n",
      " [('good', 'a'), ('squad', 'n'), ('could', None), ('small', 'a'), ('chance', 'n')] \n",
      "\n",
      "\n",
      "SentiWordNet-Word: \n",
      "\n",
      " [('good', (0.875, 0.0, 0.125)), ('squad', (0.0, 0.0, 1.0)), ('could', (0.0, 0.0, 0.0)), ('small', (0.0, 0.375, 0.625)), ('chance', (0.15, 0.025, 0.825))] \n",
      "\n",
      "\n",
      "SentiWordNet-Tweet: pos \n",
      " \t\t pos: 1.025 \n",
      " \t\t neg: 0.4 \n",
      " \t\t obj: 1.575 \n",
      "\n",
      "Example 3=====================================================\n",
      "\n",
      "Tweet: \n",
      " \n",
      " Blog: Newcastle United feedback: Will the Magpies replace like for like if they sell? http://t.co/rxfXZbGwVE #NUFC \n",
      "\n",
      "Words(tweetTokenizer): \n",
      "\n",
      " ['Blog', ':', 'Newcastle', 'United', 'feedback', ':', 'Will', 'the', 'Magpies', 'replace', 'like', 'for', 'like', 'if', 'they', 'sell', '?', 'http://t.co/rxfXZbGwVE', '#NUFC'] \n",
      "\n",
      "Words(byaCleaner): \n",
      " \n",
      " ['blog', 'newcastle', 'united', 'feedback', 'magpie', 'replace', 'like', 'like', 'sell', 'http'] \n",
      "\n",
      "\n",
      "---------------Naive Bayes--------------------------------------\n",
      "\n",
      "Naive Bayes Sentiment: pos\n",
      "\t pos: 0.8491795366795355\n",
      "\t neg: 0.15082046332046334\n",
      "\n",
      "---------------SentiWordNet--------------------------------------\n",
      "\n",
      "POS tags: \n",
      "\n",
      " [('blog', 'VB'), ('newcastle', 'NN'), ('united', 'VBN'), ('feedback', 'NN'), ('magpie', 'NNP'), ('replace', 'VB'), ('like', 'IN'), ('like', 'IN'), ('sell', 'NN'), ('http', 'NN')] \n",
      "\n",
      "\n",
      "WordNet tags: \n",
      "\n",
      " [('blog', 'v'), ('newcastle', 'n'), ('united', 'v'), ('feedback', 'n'), ('magpie', 'n'), ('replace', 'v'), ('like', None), ('like', None), ('sell', 'n'), ('http', 'n')] \n",
      "\n",
      "\n",
      "SentiWordNet-Word: \n",
      "\n",
      " [('blog', (0.0, 0.0, 1.0)), ('newcastle', (0.0, 0.0, 1.0)), ('united', (0.0, 0.020833333333333332, 0.9791666666666666)), ('feedback', (0.0, 0.0, 1.0)), ('magpie', (0.0, 0.125, 0.875)), ('replace', (0.0, 0.125, 0.875)), ('like', (0.0, 0.0, 0.0)), ('like', (0.0, 0.0, 0.0)), ('sell', (0.0, 0.0, 1.0)), ('http', (0.0, 0.0, 1.0))] \n",
      "\n",
      "\n",
      "SentiWordNet-Tweet: neg \n",
      " \t\t pos: 0.0 \n",
      " \t\t neg: 0.27083333333333337 \n",
      " \t\t obj: 2.7291666666666665 \n",
      "\n",
      "Example 4=====================================================\n",
      "\n",
      "Tweet: \n",
      " \n",
      " FourFourTwo: Knee injury sidelines Ozil http://t.co/rxfXZbGwVE #NUFC \n",
      "\n",
      "Words(tweetTokenizer): \n",
      "\n",
      " ['FourFourTwo', ':', 'Knee', 'injury', 'sidelines', 'Ozil', 'http://t.co/rxfXZbGwVE', '#NUFC'] \n",
      "\n",
      "Words(byaCleaner): \n",
      " \n",
      " ['fourfourtwo', 'knee', 'injury', 'sideline', 'ozil', 'http'] \n",
      "\n",
      "\n",
      "---------------Naive Bayes--------------------------------------\n",
      "\n",
      "Naive Bayes Sentiment: pos\n",
      "\t pos: 0.5\n",
      "\t neg: 0.5\n",
      "\n",
      "---------------SentiWordNet--------------------------------------\n",
      "\n",
      "POS tags: \n",
      "\n",
      " [('fourfourtwo', 'CD'), ('knee', 'NN'), ('injury', 'NN'), ('sideline', 'NN'), ('ozil', 'NNP'), ('http', 'NN')] \n",
      "\n",
      "\n",
      "WordNet tags: \n",
      "\n",
      " [('fourfourtwo', None), ('knee', 'n'), ('injury', 'n'), ('sideline', 'n'), ('ozil', 'n'), ('http', 'n')] \n",
      "\n",
      "\n",
      "SentiWordNet-Word: \n",
      "\n",
      " [('fourfourtwo', (0.0, 0.0, 0.0)), ('knee', (0.0, 0.0, 1.0)), ('injury', (0.0, 0.275, 0.725)), ('sideline', (0.0, 0.0, 1.0)), ('ozil', (0.0, 0.0, 0.0)), ('http', (0.0, 0.0, 1.0))] \n",
      "\n",
      "\n",
      "SentiWordNet-Tweet: neg \n",
      " \t\t pos: 0.0 \n",
      " \t\t neg: 0.275 \n",
      " \t\t obj: 0.725 \n",
      "\n",
      "Example 5=====================================================\n",
      "\n",
      "Tweet: \n",
      " \n",
      " Blog: Newcastle United coach Steve Black has got in spot on once again http://t.co/rxfXZbGwVE #NUFC \n",
      "\n",
      "Words(tweetTokenizer): \n",
      "\n",
      " ['Blog', ':', 'Newcastle', 'United', 'coach', 'Steve', 'Black', 'has', 'got', 'in', 'spot', 'on', 'once', 'again', 'http://t.co/rxfXZbGwVE', '#NUFC'] \n",
      "\n",
      "Words(byaCleaner): \n",
      " \n",
      " ['blog', 'newcastle', 'united', 'coach', 'steve', 'black', 'got', 'spot', 'http'] \n",
      "\n",
      "\n",
      "---------------Naive Bayes--------------------------------------\n",
      "\n",
      "Naive Bayes Sentiment: pos\n",
      "\t pos: 0.8458751501530617\n",
      "\t neg: 0.15412484984694033\n",
      "\n",
      "---------------SentiWordNet--------------------------------------\n",
      "\n",
      "POS tags: \n",
      "\n",
      " [('blog', 'VB'), ('newcastle', 'NN'), ('united', 'VBN'), ('coach', 'DT'), ('steve', 'VBP'), ('black', 'JJ'), ('got', 'VBD'), ('spot', 'NN'), ('http', 'NN')] \n",
      "\n",
      "\n",
      "WordNet tags: \n",
      "\n",
      " [('blog', 'v'), ('newcastle', 'n'), ('united', 'v'), ('coach', None), ('steve', 'v'), ('black', 'a'), ('got', 'v'), ('spot', 'n'), ('http', 'n')] \n",
      "\n",
      "\n",
      "SentiWordNet-Word: \n",
      "\n",
      " [('blog', (0.0, 0.0, 1.0)), ('newcastle', (0.0, 0.0, 1.0)), ('united', (0.0, 0.020833333333333332, 0.9791666666666666)), ('coach', (0.0, 0.0, 0.0)), ('steve', (0.0, 0.0, 0.0)), ('black', (0.0, 0.1875, 0.8125)), ('got', (0.034722222222222224, 0.024305555555555556, 0.9409722222222222)), ('spot', (0.03571428571428571, 0.044642857142857144, 0.9196428571428571)), ('http', (0.0, 0.0, 1.0))] \n",
      "\n",
      "\n",
      "SentiWordNet-Tweet: neg \n",
      " \t\t pos: 0.07043650793650794 \n",
      " \t\t neg: 0.27728174603174605 \n",
      " \t\t obj: 3.652281746031746 \n",
      "\n",
      "Example 6=====================================================\n",
      "\n",
      "Tweet: \n",
      " \n",
      " RT @ghanafans: KICK OFF - #Arsenal will be attacking from right to left #NUFCvAFC  #BPL \n",
      "\n",
      "Words(tweetTokenizer): \n",
      "\n",
      " ['RT', '@ghanafans', ':', 'KICK', 'OFF', '-', '#Arsenal', 'will', 'be', 'attacking', 'from', 'right', 'to', 'left', '#NUFCvAFC', '#BPL'] \n",
      "\n",
      "Words(byaCleaner): \n",
      " \n",
      " ['kick', 'attacking', 'right', 'left'] \n",
      "\n",
      "\n",
      "---------------Naive Bayes--------------------------------------\n",
      "\n",
      "Naive Bayes Sentiment: neg\n",
      "\t pos: 0.14641460479807494\n",
      "\t neg: 0.8535853952019229\n",
      "\n",
      "---------------SentiWordNet--------------------------------------\n",
      "\n",
      "POS tags: \n",
      "\n",
      " [('kick', 'NNP'), ('attacking', 'VBG'), ('right', 'JJ'), ('left', 'VBN')] \n",
      "\n",
      "\n",
      "WordNet tags: \n",
      "\n",
      " [('kick', 'n'), ('attacking', 'v'), ('right', 'a'), ('left', 'v')] \n",
      "\n",
      "\n",
      "SentiWordNet-Word: \n",
      "\n",
      " [('kick', (0.041666666666666664, 0.0625, 0.8958333333333334)), ('attacking', (0.0, 0.14583333333333334, 0.8541666666666666)), ('right', (0.35, 0.075, 0.575)), ('left', (0.0, 0.026785714285714284, 0.9732142857142857))] \n",
      "\n",
      "\n",
      "SentiWordNet-Tweet: pos \n",
      " \t\t pos: 0.39166666666666666 \n",
      " \t\t neg: 0.3101190476190476 \n",
      " \t\t obj: 3.2982142857142858 \n",
      "\n",
      "Example 7=====================================================\n",
      "\n",
      "Tweet: \n",
      " \n",
      " I hate that andre marraner he is a total cock #nufc \n",
      "\n",
      "Words(tweetTokenizer): \n",
      "\n",
      " ['I', 'hate', 'that', 'andre', 'marraner', 'he', 'is', 'a', 'total', 'cock', '#nufc'] \n",
      "\n",
      "Words(byaCleaner): \n",
      " \n",
      " ['hate', 'andre', 'marraner', 'total', 'cock'] \n",
      "\n",
      "\n",
      "---------------Naive Bayes--------------------------------------\n",
      "\n",
      "Naive Bayes Sentiment: neg\n",
      "\t pos: 0.0975000000000001\n",
      "\t neg: 0.9025000000000004\n",
      "\n",
      "---------------SentiWordNet--------------------------------------\n",
      "\n",
      "POS tags: \n",
      "\n",
      " [('hate', 'NN'), ('andre', 'VBP'), ('marraner', 'NN'), ('total', 'NN'), ('cock', 'NN')] \n",
      "\n",
      "\n",
      "WordNet tags: \n",
      "\n",
      " [('hate', 'n'), ('andre', 'v'), ('marraner', 'n'), ('total', 'n'), ('cock', 'n')] \n",
      "\n",
      "\n",
      "SentiWordNet-Word: \n",
      "\n",
      " [('hate', (0.125, 0.375, 0.5)), ('andre', (0.0, 0.0, 0.0)), ('marraner', (0.0, 0.0, 0.0)), ('total', (0.0, 0.0, 1.0)), ('cock', (0.0, 0.025, 0.975))] \n",
      "\n",
      "\n",
      "SentiWordNet-Tweet: neg \n",
      " \t\t pos: 0.125 \n",
      " \t\t neg: 0.4 \n",
      " \t\t obj: 1.475 \n",
      "\n",
      "Example 8=====================================================\n",
      "\n",
      "Tweet: \n",
      " \n",
      " Really dirty stuff from Sissoko, stomping on Nacho Monreal's ankle. Only a yellow but could have been a sending off. #Arsenal #NUFC \n",
      "\n",
      "Words(tweetTokenizer): \n",
      "\n",
      " ['Really', 'dirty', 'stuff', 'from', 'Sissoko', ',', 'stomping', 'on', 'Nacho', 'Monreal', 'is', 'ankle', '.', 'Only', 'a', 'yellow', 'but', 'could', 'have', 'been', 'a', 'sending', 'off', '.', '#Arsenal', '#NUFC'] \n",
      "\n",
      "Words(byaCleaner): \n",
      " \n",
      " ['really', 'dirty', 'stuff', 'sissoko', 'stomping', 'nacho', 'monreal', 'ankle', 'yellow', 'could', 'sending'] \n",
      "\n",
      "\n",
      "---------------Naive Bayes--------------------------------------\n",
      "\n",
      "Naive Bayes Sentiment: neg\n",
      "\t pos: 0.06074439333283354\n",
      "\t neg: 0.9392556066671645\n",
      "\n",
      "---------------SentiWordNet--------------------------------------\n",
      "\n",
      "POS tags: \n",
      "\n",
      " [('really', 'RB'), ('dirty', 'JJ'), ('stuff', 'NN'), ('sissoko', 'NN'), ('stomping', 'VBG'), ('nacho', 'NNP'), ('monreal', 'NN'), ('ankle', 'NN'), ('yellow', 'JJ'), ('could', 'MD'), ('sending', 'VBG')] \n",
      "\n",
      "\n",
      "WordNet tags: \n",
      "\n",
      " [('really', 'r'), ('dirty', 'a'), ('stuff', 'n'), ('sissoko', 'n'), ('stomping', 'v'), ('nacho', 'n'), ('monreal', 'n'), ('ankle', 'n'), ('yellow', 'a'), ('could', None), ('sending', 'v')] \n",
      "\n",
      "\n",
      "SentiWordNet-Word: \n",
      "\n",
      " [('really', (0.4375, 0.0625, 0.5)), ('dirty', (0.08333333333333333, 0.5833333333333334, 0.3333333333333333)), ('stuff', (0.017857142857142856, 0.08928571428571429, 0.8928571428571429)), ('sissoko', (0.0, 0.0, 0.0)), ('stomping', (0.0, 0.0, 1.0)), ('nacho', (0.0, 0.0, 1.0)), ('monreal', (0.0, 0.0, 0.0)), ('ankle', (0.0, 0.0, 1.0)), ('yellow', (0.0, 0.0, 0.0)), ('could', (0.0, 0.0, 0.0)), ('sending', (0.03125, 0.0, 0.96875))] \n",
      "\n",
      "\n",
      "SentiWordNet-Tweet: neg \n",
      " \t\t pos: 0.5699404761904763 \n",
      " \t\t neg: 0.7351190476190477 \n",
      " \t\t obj: 2.6949404761904763 \n",
      "\n",
      "Example 9=====================================================\n",
      "\n",
      "Tweet: \n",
      " \n",
      " Really please to make my debut for this fantastic club. Great to get the win. Now we focus on Saturdays game #toonarmy #NUFC \n",
      "\n",
      "Words(tweetTokenizer): \n",
      "\n",
      " ['Really', 'please', 'to', 'make', 'my', 'debut', 'for', 'this', 'fantastic', 'club', '.', 'Great', 'to', 'get', 'the', 'win', '.', 'Now', 'we', 'focus', 'on', 'Saturdays', 'game', '#toonarmy', '#NUFC'] \n",
      "\n",
      "Words(byaCleaner): \n",
      " \n",
      " ['really', 'please', 'make', 'debut', 'fantastic', 'club', 'great', 'get', 'win', 'focus', 'saturday', 'game'] \n",
      "\n",
      "\n",
      "---------------Naive Bayes--------------------------------------\n",
      "\n",
      "Naive Bayes Sentiment: pos\n",
      "\t pos: 0.5329823767900215\n",
      "\t neg: 0.46701762320998075\n",
      "\n",
      "---------------SentiWordNet--------------------------------------\n",
      "\n",
      "POS tags: \n",
      "\n",
      " [('really', 'RB'), ('please', 'VB'), ('make', 'VB'), ('debut', 'NN'), ('fantastic', 'JJ'), ('club', 'NN'), ('great', 'JJ'), ('get', 'VB'), ('win', 'VB'), ('focus', 'VB'), ('saturday', 'NN'), ('game', 'NN')] \n",
      "\n",
      "\n",
      "WordNet tags: \n",
      "\n",
      " [('really', 'r'), ('please', 'v'), ('make', 'v'), ('debut', 'n'), ('fantastic', 'a'), ('club', 'n'), ('great', 'a'), ('get', 'v'), ('win', 'v'), ('focus', 'v'), ('saturday', 'n'), ('game', 'n')] \n",
      "\n",
      "\n",
      "SentiWordNet-Word: \n",
      "\n",
      " [('really', (0.4375, 0.0625, 0.5)), ('please', (0.20833333333333334, 0.0, 0.7916666666666666)), ('make', (0.05357142857142857, 0.007653061224489796, 0.9387755102040817)), ('debut', (0.0, 0.0, 1.0)), ('fantastic', (0.0, 0.0, 0.0)), ('club', (0.017857142857142856, 0.0, 0.9821428571428571)), ('great', (0.0, 0.0, 0.0)), ('get', (0.034722222222222224, 0.024305555555555556, 0.9409722222222222)), ('win', (0.15625, 0.0, 0.84375)), ('focus', (0.025, 0.0, 0.975)), ('saturday', (0.0, 0.0, 1.0)), ('game', (0.022727272727272728, 0.045454545454545456, 0.9318181818181818))] \n",
      "\n",
      "\n",
      "SentiWordNet-Tweet: pos \n",
      " \t\t pos: 0.9559613997113998 \n",
      " \t\t neg: 0.1399131622345908 \n",
      " \t\t obj: 6.904125438054009 \n",
      "\n",
      "Example 10=====================================================\n",
      "\n",
      "Tweet: \n",
      " \n",
      " RT @TheSunFootball: #Arsenal break well through Sanchez and Oxlade-Chamberlain. Terrible return pass from Ramsey wrecks the move. 0-0 \n",
      "\n",
      "Words(tweetTokenizer): \n",
      "\n",
      " ['RT', '@TheSunFootball', ':', '#Arsenal', 'break', 'well', 'through', 'Sanchez', 'and', 'Oxlade-Chamberlain', '.', 'Terrible', 'return', 'pass', 'from', 'Ramsey', 'wrecks', 'the', 'move', '.', '0-0'] \n",
      "\n",
      "Words(byaCleaner): \n",
      " \n",
      " ['break', 'well', 'sanchez', 'oxlade-chamberlain', 'terrible', 'return', 'pas', 'ramsey', 'wreck', 'move', '0-0'] \n",
      "\n",
      "\n",
      "---------------Naive Bayes--------------------------------------\n",
      "\n",
      "Naive Bayes Sentiment: neg\n",
      "\t pos: 0.36759410474291915\n",
      "\t neg: 0.6324058952570791\n",
      "\n",
      "---------------SentiWordNet--------------------------------------\n",
      "\n",
      "POS tags: \n",
      "\n",
      " [('break', 'VB'), ('well', 'RB'), ('sanchez', 'NNP'), ('oxlade-chamberlain', 'VB'), ('terrible', 'JJ'), ('return', 'NN'), ('pas', 'VBD'), ('ramsey', 'NNP'), ('wreck', 'VB'), ('move', 'NN'), ('0-0', 'NN')] \n",
      "\n",
      "\n",
      "WordNet tags: \n",
      "\n",
      " [('break', 'v'), ('well', 'r'), ('sanchez', 'n'), ('oxlade-chamberlain', 'v'), ('terrible', 'a'), ('return', 'n'), ('pas', 'v'), ('ramsey', 'n'), ('wreck', 'v'), ('move', 'n'), ('0-0', 'n')] \n",
      "\n",
      "\n",
      "SentiWordNet-Word: \n",
      "\n",
      " [('break', (0.029661016949152543, 0.0423728813559322, 0.9279661016949152)), ('well', (0.44553846153846155, 0.04484615384615384, 0.5096153846153846)), ('sanchez', (0.0, 0.0, 1.0)), ('oxlade-chamberlain', (0.0, 0.0, 0.0)), ('terrible', (0.0, 0.0, 0.0)), ('return', (0.009615384615384616, 0.009615384615384616, 0.9807692307692307)), ('pas', (0.0, 0.0, 0.0)), ('ramsey', (0.0, 0.0, 0.0)), ('wreck', (0.0, 0.25, 0.75)), ('move', (0.0, 0.025, 0.975)), ('0-0', (0.0, 0.0, 0.0))] \n",
      "\n",
      "\n",
      "SentiWordNet-Tweet: pos \n",
      " \t\t pos: 0.4848148631029987 \n",
      " \t\t neg: 0.3718344198174707 \n",
      " \t\t obj: 4.143350717079531 \n",
      "\n",
      "Example 11=====================================================\n",
      "\n",
      "Tweet: \n",
      " \n",
      " RT @NUFC_Index: NUFC hunting in packs early on! \n",
      "\n",
      "Words(tweetTokenizer): \n",
      "\n",
      " ['RT', '@NUFC_Index', ':', 'NUFC', 'hunting', 'in', 'packs', 'early', 'on', '!'] \n",
      "\n",
      "Words(byaCleaner): \n",
      " \n",
      " ['nufc', 'hunting', 'pack', 'early'] \n",
      "\n",
      "\n",
      "---------------Naive Bayes--------------------------------------\n",
      "\n",
      "Naive Bayes Sentiment: neg\n",
      "\t pos: 0.2826086956521731\n",
      "\t neg: 0.7173913043478268\n",
      "\n",
      "---------------SentiWordNet--------------------------------------\n",
      "\n",
      "POS tags: \n",
      "\n",
      " [('nufc', 'NN'), ('hunting', 'VBG'), ('pack', 'NN'), ('early', 'RB')] \n",
      "\n",
      "\n",
      "WordNet tags: \n",
      "\n",
      " [('nufc', 'n'), ('hunting', 'v'), ('pack', 'n'), ('early', 'r')] \n",
      "\n",
      "\n",
      "SentiWordNet-Word: \n",
      "\n",
      " [('nufc', (0.0, 0.0, 0.0)), ('hunting', (0.0, 0.0, 1.0)), ('pack', (0.0, 0.027777777777777776, 0.9722222222222222)), ('early', (0.16666666666666666, 0.0, 0.8333333333333334))] \n",
      "\n",
      "\n",
      "SentiWordNet-Tweet: pos \n",
      " \t\t pos: 0.16666666666666666 \n",
      " \t\t neg: 0.027777777777777776 \n",
      " \t\t obj: 1.8055555555555556 \n",
      "\n",
      "Example 12=====================================================\n",
      "\n",
      "Tweet: \n",
      " \n",
      " Gets a yellow for a stamp!#nufc \n",
      "\n",
      "Words(tweetTokenizer): \n",
      "\n",
      " ['Gets', 'a', 'yellow', 'for', 'a', 'stamp', '!', '#nufc'] \n",
      "\n",
      "Words(byaCleaner): \n",
      " \n",
      " ['get', 'yellow', 'stamp'] \n",
      "\n",
      "\n",
      "---------------Naive Bayes--------------------------------------\n",
      "\n",
      "Naive Bayes Sentiment: pos\n",
      "\t pos: 0.5605355064027926\n",
      "\t neg: 0.4394644935972065\n",
      "\n",
      "---------------SentiWordNet--------------------------------------\n",
      "\n",
      "POS tags: \n",
      "\n",
      " [('get', 'VB'), ('yellow', 'JJ'), ('stamp', 'NNP')] \n",
      "\n",
      "\n",
      "WordNet tags: \n",
      "\n",
      " [('get', 'v'), ('yellow', 'a'), ('stamp', 'n')] \n",
      "\n",
      "\n",
      "SentiWordNet-Word: \n",
      "\n",
      " [('get', (0.034722222222222224, 0.024305555555555556, 0.9409722222222222)), ('yellow', (0.0, 0.0, 0.0)), ('stamp', (0.0, 0.0, 1.0))] \n",
      "\n",
      "\n",
      "SentiWordNet-Tweet: pos \n",
      " \t\t pos: 0.034722222222222224 \n",
      " \t\t neg: 0.024305555555555556 \n",
      " \t\t obj: 0.9409722222222222 \n",
      "\n",
      "Example 13=====================================================\n",
      "\n",
      "Tweet: \n",
      " \n",
      " Come on gunners! #NUFCvAFC #Arsenal \n",
      "\n",
      "Words(tweetTokenizer): \n",
      "\n",
      " ['Come', 'on', 'gunners', '!', '#NUFCvAFC', '#Arsenal'] \n",
      "\n",
      "Words(byaCleaner): \n",
      " \n",
      " ['come', 'gunner'] \n",
      "\n",
      "\n",
      "---------------Naive Bayes--------------------------------------\n",
      "\n",
      "Naive Bayes Sentiment: neg\n",
      "\t pos: 0.4480519480519479\n",
      "\t neg: 0.5519480519480517\n",
      "\n",
      "---------------SentiWordNet--------------------------------------\n",
      "\n",
      "POS tags: \n",
      "\n",
      " [('come', 'VB'), ('gunner', 'NN')] \n",
      "\n",
      "\n",
      "WordNet tags: \n",
      "\n",
      " [('come', 'v'), ('gunner', 'n')] \n",
      "\n",
      "\n",
      "SentiWordNet-Word: \n",
      "\n",
      " [('come', (0.03571428571428571, 0.005952380952380952, 0.9583333333333334)), ('gunner', (0.0, 0.0, 1.0))] \n",
      "\n",
      "\n",
      "SentiWordNet-Tweet: pos \n",
      " \t\t pos: 0.03571428571428571 \n",
      " \t\t neg: 0.005952380952380952 \n",
      " \t\t obj: 0.9583333333333334 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cleanHash(word):\n",
    "    if word[0] == '#':\n",
    "        return '#'\n",
    "    elif word[0] == '@':\n",
    "        return '@'\n",
    "    elif word[0:4] == 'http':\n",
    "        return 'http'\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "example = 1\n",
    "for tweet in tweets:\n",
    "    print(\"Example %d=====================================================\\n\" % example)\n",
    "    example += 1\n",
    "\n",
    "    print(\"Tweet: \\n \\n %s \\n\" % tweet)\n",
    "    \n",
    "    # can't -> cannot, bya's -> bya is\n",
    "    replacer = replacers.RegexpReplacer()\n",
    "    tweet = replacer.replace(tweet)\n",
    "    \n",
    "    # Tweet tokenizer\n",
    "    words = TweetTokenizer().tokenize(tweet)\n",
    "    print(\"Words(tweetTokenizer): \\n\\n %s \\n\" % words)\n",
    "    \n",
    "    # defining stopwords\n",
    "    english_stops = set(stopwords.words('english'))\n",
    "    english_stops_added = english_stops | {'.', ',', ':', ';', '#', '?', 'RT', '-', '@', 'rt'}\n",
    "    words = [word.lower() for word in words if word.lower() not in english_stops_added]\n",
    "    \n",
    "    # Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = map(lambda word: lemmatizer.lemmatize(word), words)\n",
    "\n",
    "    # words = map(lambda word: cleanHash(word), words)\n",
    "    words = [cleanHash(word) for word in words]\n",
    "    \n",
    "    # defining stopwords\n",
    "#     english_stops = set(stopwords.words('english'))\n",
    "    english_stops_added =  {'.', ',', '!', ':', ';', '#', '?', 'RT', '-', '@', 'rt'}\n",
    "    words = [word.lower() for word in words if word.lower() not in english_stops_added]\n",
    " \n",
    "    print(\"Words(byaCleaner): \\n \\n %s \\n\" % words)\n",
    "\n",
    "    print(\"\\n---------------Naive Bayes--------------------------------------\\n\")\n",
    "    \n",
    "    probs = nb_classifier.prob_classify(featx.bag_of_words(words))\n",
    "#     probs.samples()\n",
    "    print(\"Naive Bayes Sentiment: %s\" % probs.max())\n",
    "    print(\"\\t pos: %s\" % probs.prob('pos'))\n",
    "    print(\"\\t neg: %s\" % probs.prob('neg'))\n",
    "    \n",
    "    print(\"\\n---------------SentiWordNet--------------------------------------\\n\")\n",
    "    \n",
    "    taggedAUBTwords = tagger_aubt.tag(words)\n",
    "    \n",
    "    print(\"POS tags: \\n\\n %s \\n\\n\" % taggedAUBTwords)\n",
    "    \n",
    "    wordsWNtag = list(map(lambda word: senti_word_net.wordnet_sanitize(word), taggedAUBTwords))\n",
    "    \n",
    "    print(\"WordNet tags: \\n\\n %s \\n\\n\" % wordsWNtag)\n",
    "    \n",
    "    sentiWords = [(word[0], senti_word_net.senti_word_net_word(word)) for word in wordsWNtag]\n",
    "    \n",
    "    print(\"SentiWordNet-Word: \\n\\n %s \\n\\n\" % sentiWords)\n",
    "    \n",
    "    p,n,o = senti_word_net.pos_neg_score_words(wordsWNtag)\n",
    "    \n",
    "    if p > n:\n",
    "        senti = 'pos'\n",
    "    else:\n",
    "        senti = 'neg'\n",
    "    \n",
    "    print(\"SentiWordNet-Tweet: %s \\n \\t\\t pos: %s \\n \\t\\t neg: %s \\n \\t\\t obj: %s \\n\" % \n",
    "         (senti, p, n, o))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = [[2, 0, -1.4],\n",
    "     [2.2, 0.2, -1.5],\n",
    "     [2.4, 0.1, -1],\n",
    "     [1.9, 0, -1.2]]\n",
    "\n",
    "print(np.cov(np.array(X).T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "w, v = np.linalg.eig(np.array([[1, -2], [2, -3]]))\n",
    "w; v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction with Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "data = load_iris()\n",
    "y = data.target\n",
    "X = data.data\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot reduced data\n",
    "\n",
    "red_x, red_y = [], []\n",
    "blue_x, blue_y = [], []\n",
    "green_x, green_y = [], []\n",
    "\n",
    "for i in range(len(reduced_X)):\n",
    "    if y[i] == 0:\n",
    "        red_x.append(reduced_X[i][0])\n",
    "        red_y.append(reduced_X[i][1])\n",
    "    elif y[i] == 1:\n",
    "        blue_x.append(reduced_X[i][0])\n",
    "        blue_y.append(reduced_X[i][1])\n",
    "    else:\n",
    "        green_x.append(reduced_X[i][0])\n",
    "        green_y.append(reduced_X[i][1])\n",
    "\n",
    "plt.scatter(red_x, red_y, c='r', marker='x')\n",
    "plt.scatter(blue_x, blue_y, c='b', marker='D')\n",
    "plt.scatter(green_x, green_y, c='g', marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face recognition with PCA\n",
    "\n",
    "The data set contains ten images each of forty people.\n",
    "The images were created under different lighting conditions, and the subjects varied their facial expressions. The images are gray scale and 92 x 112 pixels in dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from os import walk, path\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Bya/.virtualenvs/py3/lib/python3.4/site-packages/sklearn/preprocessing/data.py:153: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/Users/Bya/.virtualenvs/py3/lib/python3.4/site-packages/sklearn/preprocessing/data.py:169: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "\n",
    "# Load Images\n",
    "\n",
    "\n",
    "for dir_path, dir_names, file_names in walk('/Users/Bya/Dropbox/Research/resources/orl_faces/'):\n",
    "    for fn in file_names:\n",
    "        if fn[-3:] == 'pgm':\n",
    "            image_filename = path.join(dir_path, fn)\n",
    "            X.append(scale(mh.imread(image_filename, as_grey=True).reshape(10304).astype('float32')))\n",
    "            y.append(dir_path)\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dimensions of the training data were (300, 10304)\n",
      "The reduced dimensions of the training data are (300, 150)\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "\n",
    "# Reshape matrices to vectors\n",
    "# Randomly split to: Train, Test data\n",
    "\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# fit PCA\n",
    "pca = PCA(n_components=150)\n",
    "\n",
    "# train, test data\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "print('The original dimensions of the training data were', X_train.shape)\n",
    "print('The reduced dimensions of the training data are', X_train_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation accuracy: 0.801700634665 [ 0.84070796  0.75757576  0.80681818]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s1       0.67      1.00      0.80         2\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s10       1.00      1.00      1.00         2\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s11       1.00      1.00      1.00         1\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s12       1.00      1.00      1.00         3\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s13       1.00      1.00      1.00         3\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s14       1.00      1.00      1.00         4\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s15       1.00      1.00      1.00         4\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s16       1.00      1.00      1.00         4\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s17       1.00      1.00      1.00         3\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s18       1.00      1.00      1.00         3\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s19       1.00      1.00      1.00         2\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s2       1.00      1.00      1.00         4\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s20       1.00      1.00      1.00         3\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s21       1.00      1.00      1.00         2\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s22       1.00      1.00      1.00         3\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s23       0.67      1.00      0.80         2\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s24       1.00      1.00      1.00         1\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s25       1.00      1.00      1.00         1\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s26       1.00      1.00      1.00         2\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s27       1.00      1.00      1.00         2\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s28       1.00      1.00      1.00         1\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s29       1.00      1.00      1.00         3\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s3       1.00      1.00      1.00         3\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s30       1.00      0.75      0.86         4\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s31       0.00      0.00      0.00         0\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s32       1.00      0.67      0.80         6\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s33       1.00      0.50      0.67         2\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s34       1.00      1.00      1.00         3\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s35       1.00      0.50      0.67         2\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s36       0.67      1.00      0.80         2\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s37       1.00      1.00      1.00         2\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s38       1.00      1.00      1.00         1\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s39       1.00      1.00      1.00         1\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s4       1.00      1.00      1.00         4\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s40       1.00      0.67      0.80         3\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s5       0.75      0.75      0.75         4\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s6       0.50      1.00      0.67         1\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s7       1.00      1.00      1.00         3\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s8       1.00      1.00      1.00         1\n",
      "/Users/Bya/Dropbox/Research/resources/orl_faces/s9       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       0.96      0.93      0.94       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Bya/.virtualenvs/py3/lib/python3.4/site-packages/sklearn/metrics/classification.py:960: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "\n",
    "# Logistic regression classifier\n",
    "# (The data set contains forty classes)\n",
    "# scikit-learn automatically creates binary classifiers\n",
    "# using the one-versus-all strategy behind the scenes:\n",
    "\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "accuracies = cross_val_score(classifier, X_train_reduced, y_train)\n",
    "\n",
    "print('Cross validation accuracy:\\n', np.mean(accuracies), accuracies)\n",
    "\n",
    "classifier.fit(X_train_reduced, y_train)\n",
    "predictions = classifier.predict(X_test_reduced)\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

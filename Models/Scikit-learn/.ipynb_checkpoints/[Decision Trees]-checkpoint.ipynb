{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import codecs\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "sys.path.append(\"/Users/Bya/git/predictEPL/utils/\")\n",
    "sys.path.append(\"/Users/Bya/git/predictEPL/config/\")\n",
    "\n",
    "import emolex\n",
    "import paths\n",
    "import tokenizer\n",
    "import useful_methods as my_methods\n",
    "import train_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[list(explanatory_variable_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Bya/.virtualenvs/py3/lib/python3.4/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "\n",
    "# Step 1. Data Load\n",
    "os.chdir(\"/Users/Bya/Dropbox/Research/resources/ad-dataset/\")\n",
    "\n",
    "df = pd.read_csv('ad.data.txt', header=None)\n",
    "explanatory_variable_columns = set(df.columns.values)\n",
    "response_variable_column = df[len(df.columns.values)-1]\n",
    "\n",
    "# The last column describes the targets\n",
    "explanatory_variable_columns.remove(len(df.columns.values)-1)\n",
    "y = [1 if e == 'ad.' else 0 for e in response_variable_column]\n",
    "X = df[list(explanatory_variable_columns)]\n",
    "\n",
    "\n",
    "# missing values to '-1'\n",
    "X.replace(to_replace=' *\\?', value=-1, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "\n",
    "# Step 2. Split datas\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "##############################\n",
    "\n",
    "# Step 3. Set params, grid search\n",
    "\n",
    "\n",
    "# Pipelines\n",
    "pipeline = Pipeline([\n",
    "        ('clf', DecisionTreeClassifier(criterion='entropy'))\n",
    "])\n",
    "\n",
    "\n",
    "# Hyper Parameters\n",
    "parameters = {\n",
    "    'clf__max_depth': (150, 155, 160),\n",
    "    'clf__min_samples_split': (1, 2, 3),\n",
    "    'clf__min_samples_leaf': (1, 2, 3)\n",
    "}\n",
    "\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    parameters,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  81 | elapsed:  2.0min remaining:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.884\n",
      "Best parameters set:\n",
      "\tclf__max_depth: 155\n",
      "\tclf__min_samples_leaf: 2\n",
      "\tclf__min_samples_split: 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99       705\n",
      "          1       0.96      0.87      0.91       115\n",
      "\n",
      "avg / total       0.98      0.98      0.98       820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "\n",
    "# Step 4. Compute\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best score, params\n",
    "print('Best score: %0.3f' % grid_search.best_score_)\n",
    "print('Best parameters set:')\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "# Test results    \n",
    "predictions = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('clf', RandomForestClassifier(criterion='entropy'))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__n_estimators': (5, 10, 20, 50),\n",
    "    'clf__max_depth': (50, 150, 250),\n",
    "    'clf__min_samples_split': (1, 2, 3),\n",
    "    'clf__min_samples_leaf': (1, 2, 3)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    parameters,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring='f1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 200 jobs       | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 318 out of 324 | elapsed:  9.8min remaining:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed: 10.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.914\n",
      "Best parameters set:\n",
      "\tclf__max_depth: 250\n",
      "\tclf__min_samples_leaf: 1\n",
      "\tclf__min_samples_split: 2\n",
      "\tclf__n_estimators: 50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       705\n",
      "          1       0.98      0.89      0.93       115\n",
      "\n",
      "avg / total       0.98      0.98      0.98       820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "\n",
    "# Step 4. Compute\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best score, params\n",
    "print('Best score: %0.3f' % grid_search.best_score_)\n",
    "print('Best parameters set:')\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "# Test results    \n",
    "predictions = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import codecs\n",
    "import collections\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "sys.path.append(\"/Users/Bya/git/predictEPL/utils/\")\n",
    "sys.path.append(\"/Users/Bya/git/predictEPL/config/\")\n",
    "sys.path.append(\"/Users/Bya/git/predictEPL/WebScrapping/\")\n",
    "\n",
    "import paths\n",
    "import useful_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "short_pos = codecs.open(paths.READ_PATH_REVIEW_SHORT + \"positive1.txt\", encoding='utf-8').read()\n",
    "short_neg = codecs.open(paths.READ_PATH_REVIEW_SHORT + \"negative1.txt\", encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Positive Reviews:  5332\n",
      "Short Negative Reviews:  5332\n"
     ]
    }
   ],
   "source": [
    "# create labeled documents\n",
    "documents = []\n",
    "\n",
    "for r in short_pos.split('\\n'):\n",
    "    documents.append( (r, \"pos\") )\n",
    "\n",
    "short_pos_len = len(documents)\n",
    "\n",
    "for r in short_neg.split('\\n'):\n",
    "    documents.append( (r, \"neg\") )\n",
    "\n",
    "short_neg_len = len(documents) - short_pos_len\n",
    "\n",
    "print(\"Short Positive Reviews: \", short_pos_len)\n",
    "print (\"Short Negative Reviews: \", short_neg_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All words number:  115953\n"
     ]
    }
   ],
   "source": [
    "# create all words lists\n",
    "all_words = []\n",
    "\n",
    "short_pos_words = useful_methods.tokenizer(short_pos)\n",
    "short_neg_words = useful_methods.tokenizer(short_neg)\n",
    "\n",
    "for w in short_pos_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "for w in short_neg_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "print(\"All words number: \", len(all_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get most frequent 5000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All unique words:  14456\n"
     ]
    }
   ],
   "source": [
    "print(\"All unique words: \", len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_word_features = open(paths.READ_PATH_REVIEW_SHORT + \"word_features5k_shortReviews.pickle\",\"wb\")\n",
    "pickle.dump(word_features, save_word_features)\n",
    "save_word_features.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = useful_methods.tokenizer(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.68\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "print(\"%.2f\" %(time.time() -start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle all sets\n",
    "random.shuffle(featuresets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  8000\n",
      "Testing data:  2664\n"
     ]
    }
   ],
   "source": [
    "training_set = featuresets[:8000]\n",
    "testing_set =  featuresets[8000:]\n",
    "\n",
    "print(\"Training data: \", len(training_set))\n",
    "print(\"Testing data: \", len(testing_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.84\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "print(\"%.2f\" %(time.time() -start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes algo accuracy percent: 68.20570570570571\n",
      "82.60\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print(\"Original Naive Bayes algo accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "\n",
    "print(\"%.2f\" %(time.time() -start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   intim = True              pos : neg    =     14.6 : 1.0\n",
      "                    bore = True              neg : pos    =     13.9 : 1.0\n",
      "                 refresh = True              pos : neg    =     13.9 : 1.0\n",
      "                  tender = True              pos : neg    =     11.8 : 1.0\n",
      "                    flat = True              neg : pos    =     11.2 : 1.0\n",
      "                   dazzl = True              pos : neg    =     11.2 : 1.0\n",
      "                     son = True              pos : neg    =     11.2 : 1.0\n",
      "                  stupid = True              neg : pos    =     10.8 : 1.0\n",
      "                  clumsi = True              neg : pos    =      8.2 : 1.0\n",
      "                     gem = True              pos : neg    =      7.8 : 1.0\n",
      "                polanski = True              pos : neg    =      7.8 : 1.0\n",
      "                 shallow = True              neg : pos    =      7.5 : 1.0\n",
      "                    sink = True              neg : pos    =      7.5 : 1.0\n",
      "                    tire = True              neg : pos    =      7.2 : 1.0\n",
      "                    sour = True              neg : pos    =      6.9 : 1.0\n",
      "                   stiff = True              neg : pos    =      6.9 : 1.0\n",
      "                 russian = True              pos : neg    =      6.4 : 1.0\n",
      "                 delight = True              pos : neg    =      6.3 : 1.0\n",
      "                 maudlin = True              neg : pos    =      6.2 : 1.0\n",
      "                artifici = True              neg : pos    =      6.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo of Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Review: \n",
      " there are some wonderfully fresh moments that smooth the moral stiffness with human kindness and hopefulness . \n",
      "Result of Naive Bayes Classifier: \n",
      " pos\n",
      "\n",
      "Negative Review: \n",
      " a broad , melodramatic estrogen opera that's pretty toxic in its own right . \n",
      "Result of Naive Bayes Classifier: \n",
      " neg\n"
     ]
    }
   ],
   "source": [
    "example_pos = short_pos.split('\\n')[random.randint(0, len(short_pos.split('\\n')) - 1)]\n",
    "example_neg = short_neg.split('\\n')[random.randint(0, len(short_neg.split('\\n')) - 1)]\n",
    "\n",
    "print(\"Positive Review: \\n\", example_pos)\n",
    "print(\"Result of Naive Bayes Classifier: \\n\", classifier.classify(find_features(example_pos)))\n",
    "\n",
    "print(\"\\nNegative Review: \\n\", example_neg)\n",
    "print(\"Result of Naive Bayes Classifier: \\n\", classifier.classify(find_features(example_neg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_classifier = open(paths.READ_PATH_REVIEW_SHORT + \"naiveBayes_for_short_reviews_5k.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using save Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saved_classifier_f = open(paths.READ_PATH_REVIEW_SHORT + \"naiveBayes_for_short_reviews_5k.pickle\", \"rb\")\n",
    "saved_classifier = pickle.load(saved_classifier_f)\n",
    "saved_classifier_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Review: \n",
      " there are some wonderfully fresh moments that smooth the moral stiffness with human kindness and hopefulness . \n",
      "Result of Naive Bayes Classifier: \n",
      " pos\n",
      "\n",
      "[Passed Time]:0.04\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print(\"Positive Review: \\n\", example_pos)\n",
    "print(\"Result of Naive Bayes Classifier: \\n\", classifier.classify(find_features(example_pos)))\n",
    "\n",
    "print(\"\\n[Passed Time]:%.2f\" %(time.time() -start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

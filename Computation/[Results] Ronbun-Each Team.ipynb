{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Global Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import datetime\n",
    "from time import gmtime, strftime\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "\n",
    "# Scikit-Learn imports\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# Local Imports\n",
    "path = str(os.path.expanduser('~')) + '/git/predictEPL/config'\n",
    "sys.path.append(path)\n",
    "import paths\n",
    "\n",
    "sys.path.append(paths.UTILS)\n",
    "import useful_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ReadEmolexDf():\n",
    "    # Read game_infos as df\n",
    "    dfGameInfo = useful_methods.csv_dic_df(paths.READ_PATH_GAME_INFO + 'game_infos.csv')\n",
    "    dfGameInfo = useful_methods.DropNanGames(dfGameInfo).copy().reset_index(drop=True)\n",
    "    dfGameInfo.GW = [int(gw) for gw in dfGameInfo.GW]\n",
    "    dfGameInfo = dfGameInfo.sort_values(['GW', 'away_team'], ascending=[True, True]).copy().reset_index(drop=True)\n",
    "\n",
    "    # Read Hash Emolex Model result\n",
    "    df = useful_methods.csv_dic_df(paths.READ_PATH_RESULTS + RESULT_FILE_NAME)\n",
    "    df.GW = [int(gw) for gw in df.GW]\n",
    "    df = df.sort_values(['GW', 'away_team'], ascending=[True, True]).copy().reset_index(drop=True)\n",
    "\n",
    "    df.emolex_home = [np.array([float(emo.strip()) for emo in emolex_home[1:-2].split('.')]) for emolex_home in list(df.emolex_home)]\n",
    "    df.emolex_away = [np.array([float(emo.strip()) for emo in emolex_away[1:-2].split('.')]) for emolex_away in list(df.emolex_away)]\n",
    "\n",
    "\n",
    "    # Combine 2 dfs\n",
    "    df['score_ht_away'] = [int(item) for item in dfGameInfo.score_ht_away]\n",
    "    df['score_ht_home'] = [int(item) for item in dfGameInfo.score_ht_home]\n",
    "    df['score_ft_away'] = [int(item) for item in dfGameInfo.score_ft_away]\n",
    "    df['score_ft_home'] = [int(item) for item in dfGameInfo.score_ft_home]\n",
    "\n",
    "    # 'home_win': 1, 'away_win': 0, 'draw': 2\n",
    "    def Labeling(goal_diff):\n",
    "        if goal_diff > 0:\n",
    "            return 1\n",
    "        elif goal_diff < 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "    df['goal_diff_ht'] = df.score_ht_home - df.score_ht_away\n",
    "    df['goal_diff_ft'] = df.score_ft_home - df.score_ft_away\n",
    "    df['result'] = [Labeling(item) for item in df.goal_diff_ft]\n",
    "\n",
    "\n",
    "    # **********************************************\n",
    "    # Add previous 4 games points sum\n",
    "    dfBe4GameSum = useful_methods.csv_dic_df(paths.DATA_HOME + \"EPL/info_before_4game_sum.csv\")\n",
    "\n",
    "    team_homes = list(df.home_team)\n",
    "    team_aways = list(df.away_team)\n",
    "    GWs = [int(gw) for gw in df.GW]\n",
    "\n",
    "    be_4game_sum_home = []\n",
    "    be_4game_sum_away = []\n",
    "\n",
    "    for index in range(len(GWs)):\n",
    "        team_home = team_homes[index]\n",
    "        team_away = team_aways[index]\n",
    "        gw = GWs[index]\n",
    "\n",
    "        be_4game_sum_home.append(int(dfBe4GameSum[dfBe4GameSum.team == team_home][str(gw)]))\n",
    "        be_4game_sum_away.append(int(dfBe4GameSum[dfBe4GameSum.team == team_away][str(gw)]))\n",
    "\n",
    "    df['be_4game_sum_away'] = be_4game_sum_away\n",
    "    df['be_4game_sum_home'] = be_4game_sum_home    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create df for models.\n",
    "def CreateDfForModel(ht_draw=False, ft_wld=False):\n",
    "    df = ReadEmolexDf()\n",
    "        \n",
    "    # only for Win or Lose\n",
    "    if not ft_wld:\n",
    "        df = df[df.result != 2].copy().reset_index(drop=True)\n",
    "    \n",
    "    # HT: Equal\n",
    "    if ht_draw:\n",
    "        df = df[df.goal_diff_ht == 0].copy().reset_index(drop=True)\n",
    "    \n",
    "    dta = pd.DataFrame()\n",
    "    \n",
    "    # Teams\n",
    "    dta['team_home'] = df.home_team\n",
    "    dta['team_away'] = df.away_team\n",
    "    \n",
    "    # HF scores\n",
    "    dta['score_ht_home'] = df.score_ht_home\n",
    "    dta['score_ht_away'] = df.score_ht_away\n",
    "    \n",
    "    dta['goal_diff_ht'] = df['goal_diff_ht']\n",
    "    dta['goal_diff_ft'] = df['goal_diff_ft']\n",
    "\n",
    "    # 'home_win': 1, 'away_win': 0, 'draw': 2\n",
    "    dta['result'] = df.result\n",
    "    \n",
    "    # be_4game_sum\n",
    "    dta['be_4game_sum_home'] = df.be_4game_sum_home / 12.0\n",
    "    dta['be_4game_sum_away'] = df.be_4game_sum_away / 12.0\n",
    "    \n",
    "    # Emolex 8\n",
    "    dta['anger_home'] = [emolex[0] / sum(emolex[:-2]) for emolex in df.emolex_home]\n",
    "    dta['fear_home'] = [emolex[1] / sum(emolex[:-2]) for emolex in df.emolex_home]\n",
    "    dta['disgust_home'] = [emolex[2] / sum(emolex[:-2]) for emolex in df.emolex_home]\n",
    "    dta['sadness_home'] = [emolex[3] / sum(emolex[:-2])  for emolex in df.emolex_home]\n",
    "    dta['surprise_home'] = [emolex[4] / sum(emolex[:-2])  for emolex in df.emolex_home]\n",
    "    dta['trust_home'] = [emolex[5] / sum(emolex[:-2])  for emolex in df.emolex_home]\n",
    "    dta['joy_home'] = [emolex[6] / sum(emolex[:-2])  for emolex in df.emolex_home]\n",
    "    dta['anticipation_home'] = [emolex[7] / sum(emolex[:-2])  for emolex in df.emolex_home]\n",
    "    dta['pos_home'] = [emolex[8] / sum(emolex[-2:])  for emolex in df.emolex_home]\n",
    "    dta['neg_home'] = [emolex[9] / sum(emolex[-2:])  for emolex in df.emolex_home]\n",
    "\n",
    "    dta['anger_away'] = [emolex[0] / sum(emolex[:-2])  for emolex in df.emolex_away]\n",
    "    dta['fear_away'] = [emolex[1] / sum(emolex[:-2])  for emolex in df.emolex_away]\n",
    "    dta['disgust_away'] = [emolex[2] / sum(emolex[:-2])  for emolex in df.emolex_away]\n",
    "    dta['sadness_away'] = [emolex[3] / sum(emolex[:-2])  for emolex in df.emolex_away]\n",
    "    dta['surprise_away'] = [emolex[4] / sum(emolex[:-2])  for emolex in df.emolex_away]\n",
    "    dta['trust_away'] = [emolex[5] / sum(emolex[:-2])  for emolex in df.emolex_away]\n",
    "    dta['joy_away'] = [emolex[6] / sum(emolex[:-2])  for emolex in df.emolex_away]\n",
    "    dta['anticipation_away'] = [emolex[7] / sum(emolex[:-2])  for emolex in df.emolex_away]\n",
    "    dta['pos_away'] = [emolex[8] / sum(emolex[-2:])  for emolex in df.emolex_away]\n",
    "    dta['neg_away'] = [emolex[9] / sum(emolex[-2:])  for emolex in df.emolex_away]\n",
    "    \n",
    "    \n",
    "    # Diffs\n",
    "    dta['diff_anger'] = dta['anger_home'] - dta['anger_away']\n",
    "    dta['diff_fear'] = dta['fear_home'] - dta['fear_away']\n",
    "    dta['diff_disgust'] = dta['disgust_home'] - dta['disgust_away']\n",
    "    dta['diff_sadness'] = dta['sadness_home'] - dta['sadness_away']\n",
    "    dta['diff_surprise'] = dta['surprise_home'] - dta['surprise_away']\n",
    "    dta['diff_trust'] = dta['trust_home'] - dta['trust_away']\n",
    "    dta['diff_joy'] = dta['joy_home'] - dta['joy_away']\n",
    "    dta['diff_anticipation'] = dta['anticipation_home'] - dta['anticipation_away']\n",
    "    dta['diff_pos'] = dta['pos_home'] - dta['pos_away']\n",
    "    dta['diff_neg'] = dta['neg_home'] - dta['neg_away']\n",
    "    \n",
    "    \n",
    "    return dta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODDS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ReadOddsDf():\n",
    "    # Read Scores\n",
    "    dfOdds = useful_methods.OddsPortalDf()\n",
    "\n",
    "    df = dfOdds.copy()\n",
    "    drop_index = []\n",
    "\n",
    "    # drop Nan Games\n",
    "    for ith_row in range(len(df)):\n",
    "        # Team names\n",
    "        week = df.iloc[ith_row]['GW']\n",
    "        team_home = df.iloc[ith_row]['team_home']\n",
    "        team_away = df.iloc[ith_row]['team_away']\n",
    "\n",
    "        isFile = os.path.isfile(\n",
    "        \"/Users/Bya/Dropbox/Research/datas/EPL/ExtractedCsvData/\" + \"GW\" + str(int(week)) + \"/SingleGames/\" + \\\n",
    "        team_home + \"_vs_\" + team_away + \".csv\")\n",
    "\n",
    "        if not isFile:\n",
    "            drop_index.append(ith_row)\n",
    "\n",
    "    df = df.drop(df.index[drop_index]).copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # str to int\n",
    "    str_to_num_cols = [\"score_ft_home\", \"score_ft_away\", \"odds_home\", \"odds_away\", \"odds_draw\"]\n",
    "\n",
    "    for col in str_to_num_cols:\n",
    "        df[col] = [np.float(item) for item in df[col]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateDfForModelOdds(ft_wld=True):\n",
    "    df = CreateDfForModel(ft_wld=ft_wld)\n",
    "    dfOdds = ReadOddsDf()\n",
    "\n",
    "    odds_homes = []\n",
    "    odds_aways = []\n",
    "    odds_draws = []\n",
    "\n",
    "    for ith_row in range(len(df)):\n",
    "        team_home = df.loc[ith_row]['team_home']\n",
    "        team_away = df.loc[ith_row]['team_away']\n",
    "\n",
    "        odds_home = dfOdds[(dfOdds.team_home == team_home) & (dfOdds.team_away == team_away)]['odds_home']\n",
    "        odds_away = dfOdds[(dfOdds.team_home == team_home) & (dfOdds.team_away == team_away)]['odds_away']\n",
    "        odds_draw = dfOdds[(dfOdds.team_home == team_home) & (dfOdds.team_away == team_away)]['odds_draw']\n",
    "\n",
    "        odds_homes.append(np.float(odds_home))\n",
    "        odds_aways.append(np.float(odds_away))\n",
    "        odds_draws.append(np.float(odds_draw))\n",
    "\n",
    "    df['odds_home'] = odds_homes\n",
    "    df['odds_away'] = odds_aways\n",
    "    df['odds_draw'] = odds_draws\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Emolex Log Model: Each Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Single Team Accuracu Score and Report\n",
    "def SingleTeamAccuracy(df, team):\n",
    "    print(\"\\n==============================\")\n",
    "    print(team, \":\\n\")\n",
    "    \n",
    "    dfTeam = df[(df.team_home == team) | (df.team_away == team)].copy().reset_index(drop=True)\n",
    "\n",
    "    # Create X, y for model\n",
    "    y, X = dmatrices(\n",
    "        'result ~ \\\n",
    "        anger_home + fear_home + disgust_home + sadness_home + \\\n",
    "        surprise_home + trust_home + joy_home + anticipation_home + \\\n",
    "        anger_away + fear_away + disgust_away + sadness_away + \\\n",
    "        surprise_away + trust_away + joy_away + anticipation_away + \\\n",
    "        pos_home + neg_home + pos_away + neg_away + \\\n",
    "        diff_anger + diff_fear + diff_disgust + diff_sadness + diff_surprise + \\\n",
    "        diff_trust + diff_joy + diff_anticipation + diff_pos + diff_neg',\n",
    "        dfTeam, return_type=\"dataframe\")\n",
    "    y = np.ravel(y)\n",
    "\n",
    "\n",
    "    # prediction reports\n",
    "    predictions = model.predict(X)\n",
    "    print(metrics.confusion_matrix(y, predictions))\n",
    "    print(metrics.classification_report(y, predictions))\n",
    "    print(metrics.accuracy_score(y, predictions))\n",
    "    accuracy_score = metrics.accuracy_score(y, predictions)\n",
    "\n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Arsenal :\n",
      "\n",
      "[[2 3 0]\n",
      " [1 9 0]\n",
      " [1 2 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.40      0.44         5\n",
      "        1.0       0.64      0.90      0.75        10\n",
      "        2.0       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.50      0.61      0.54        18\n",
      "\n",
      "0.611111111111\n",
      "\n",
      "==============================\n",
      "Bournemouth :\n",
      "\n",
      "[[3 1 0]\n",
      " [0 8 0]\n",
      " [2 4 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.60      0.75      0.67         4\n",
      "        1.0       0.62      1.00      0.76         8\n",
      "        2.0       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.41      0.61      0.49        18\n",
      "\n",
      "0.611111111111\n",
      "\n",
      "==============================\n",
      "Chelsea :\n",
      "\n",
      "[[3 2 0]\n",
      " [0 6 0]\n",
      " [2 4 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.60      0.60      0.60         5\n",
      "        1.0       0.50      1.00      0.67         6\n",
      "        2.0       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.35      0.53      0.41        17\n",
      "\n",
      "0.529411764706\n",
      "\n",
      "==============================\n",
      "City :\n",
      "\n",
      "[[2 2 0]\n",
      " [1 9 0]\n",
      " [1 3 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.50      0.50         4\n",
      "        1.0       0.64      0.90      0.75        10\n",
      "        2.0       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.47      0.61      0.53        18\n",
      "\n",
      "0.611111111111\n",
      "\n",
      "==============================\n",
      "Crystal :\n",
      "\n",
      "[[3 3 0]\n",
      " [0 7 0]\n",
      " [1 3 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      0.50      0.60         6\n",
      "        1.0       0.54      1.00      0.70         7\n",
      "        2.0       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.49      0.59      0.50        17\n",
      "\n",
      "0.588235294118\n",
      "\n",
      "==============================\n",
      "Everton :\n",
      "\n",
      "[[5 1 0]\n",
      " [0 4 0]\n",
      " [5 3 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.83      0.62         6\n",
      "        1.0       0.50      1.00      0.67         4\n",
      "        2.0       0.00      0.00      0.00         8\n",
      "\n",
      "avg / total       0.28      0.50      0.36        18\n",
      "\n",
      "0.5\n",
      "\n",
      "==============================\n",
      "Leicester :\n",
      "\n",
      "[[4 3 0]\n",
      " [2 2 0]\n",
      " [1 5 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.57      0.57      0.57         7\n",
      "        1.0       0.20      0.50      0.29         4\n",
      "        2.0       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.28      0.35      0.30        17\n",
      "\n",
      "0.352941176471\n",
      "\n",
      "==============================\n",
      "Liverpool :\n",
      "\n",
      "[[1 4 0]\n",
      " [2 5 0]\n",
      " [2 4 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.20      0.20      0.20         5\n",
      "        1.0       0.38      0.71      0.50         7\n",
      "        2.0       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.21      0.33      0.25        18\n",
      "\n",
      "0.333333333333\n",
      "\n",
      "==============================\n",
      "Newcastle :\n",
      "\n",
      "[[3 1 0]\n",
      " [2 8 0]\n",
      " [1 3 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.75      0.60         4\n",
      "        1.0       0.67      0.80      0.73        10\n",
      "        2.0       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.48      0.61      0.54        18\n",
      "\n",
      "0.611111111111\n",
      "\n",
      "==============================\n",
      "Norwich :\n",
      "\n",
      "[[3 1 0]\n",
      " [1 9 0]\n",
      " [1 3 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.60      0.75      0.67         4\n",
      "        1.0       0.69      0.90      0.78        10\n",
      "        2.0       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.52      0.67      0.58        18\n",
      "\n",
      "0.666666666667\n",
      "\n",
      "==============================\n",
      "Southampton :\n",
      "\n",
      "[[3 2 0]\n",
      " [1 8 0]\n",
      " [3 1 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.43      0.60      0.50         5\n",
      "        1.0       0.73      0.89      0.80         9\n",
      "        2.0       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.48      0.61      0.54        18\n",
      "\n",
      "0.611111111111\n",
      "\n",
      "==============================\n",
      "Stoke :\n",
      "\n",
      "[[5 1 0]\n",
      " [0 8 0]\n",
      " [2 2 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.83      0.77         6\n",
      "        1.0       0.73      1.00      0.84         8\n",
      "        2.0       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.56      0.72      0.63        18\n",
      "\n",
      "0.722222222222\n",
      "\n",
      "==============================\n",
      "Sunderland :\n",
      "\n",
      "[[2 3 0]\n",
      " [3 8 0]\n",
      " [1 1 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.33      0.40      0.36         5\n",
      "        1.0       0.67      0.73      0.70        11\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.50      0.56      0.53        18\n",
      "\n",
      "0.555555555556\n",
      "\n",
      "==============================\n",
      "Swansea :\n",
      "\n",
      "[[4 2 0]\n",
      " [2 5 0]\n",
      " [1 4 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.57      0.67      0.62         6\n",
      "        1.0       0.45      0.71      0.56         7\n",
      "        2.0       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.37      0.50      0.42        18\n",
      "\n",
      "0.5\n",
      "\n",
      "==============================\n",
      "Tottenham :\n",
      "\n",
      "[[2 5 0]\n",
      " [1 5 0]\n",
      " [2 3 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.40      0.29      0.33         7\n",
      "        1.0       0.38      0.83      0.53         6\n",
      "        2.0       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.28      0.39      0.31        18\n",
      "\n",
      "0.388888888889\n",
      "\n",
      "==============================\n",
      "United :\n",
      "\n",
      "[[3 2 0]\n",
      " [1 5 0]\n",
      " [1 5 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.60      0.60      0.60         5\n",
      "        1.0       0.42      0.83      0.56         6\n",
      "        2.0       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.32      0.47      0.37        17\n",
      "\n",
      "0.470588235294\n",
      "\n",
      "==============================\n",
      "Villa :\n",
      "\n",
      "[[4 1 0]\n",
      " [1 7 0]\n",
      " [3 2 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.80      0.62         5\n",
      "        1.0       0.70      0.88      0.78         8\n",
      "        2.0       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.45      0.61      0.52        18\n",
      "\n",
      "0.611111111111\n",
      "\n",
      "==============================\n",
      "Watford :\n",
      "\n",
      "[[3 4 0]\n",
      " [0 7 0]\n",
      " [1 1 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      0.43      0.55         7\n",
      "        1.0       0.58      1.00      0.74         7\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.58      0.62      0.56        16\n",
      "\n",
      "0.625\n",
      "\n",
      "==============================\n",
      "WestBromwich :\n",
      "\n",
      "[[3 2 0]\n",
      " [1 6 0]\n",
      " [1 5 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.60      0.60      0.60         5\n",
      "        1.0       0.46      0.86      0.60         7\n",
      "        2.0       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.35      0.50      0.40        18\n",
      "\n",
      "0.5\n",
      "\n",
      "==============================\n",
      "WestHam :\n",
      "\n",
      "[[2 1 0]\n",
      " [1 6 0]\n",
      " [2 6 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.40      0.67      0.50         3\n",
      "        1.0       0.46      0.86      0.60         7\n",
      "        2.0       0.00      0.00      0.00         8\n",
      "\n",
      "avg / total       0.25      0.44      0.32        18\n",
      "\n",
      "0.444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Bya/.virtualenvs/py3/lib/python3.4/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.61111111111111116,\n",
       " 0.61111111111111116,\n",
       " 0.52941176470588236,\n",
       " 0.61111111111111116,\n",
       " 0.58823529411764708,\n",
       " 0.5,\n",
       " 0.35294117647058826,\n",
       " 0.33333333333333331,\n",
       " 0.61111111111111116,\n",
       " 0.66666666666666663,\n",
       " 0.61111111111111116,\n",
       " 0.72222222222222221,\n",
       " 0.55555555555555558,\n",
       " 0.5,\n",
       " 0.3888888888888889,\n",
       " 0.47058823529411764,\n",
       " 0.61111111111111116,\n",
       " 0.625,\n",
       " 0.5,\n",
       " 0.44444444444444442]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==================================================\n",
    "# Read Model\n",
    "MODEL_EMOLEX_WL_LOG = \"model_emolex_wld_log.pkl\"\n",
    "with open(paths.DATA_HOME + 'Models/' + MODEL_EMOLEX_WL_LOG, 'rb') as f:\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'utf-8'\n",
    "    model = u.load()\n",
    "    \n",
    "\n",
    "# ==================================================\n",
    "# File Name\n",
    "RESULT_FILE_NAME = \"emolex_all_ht.csv\"\n",
    "\n",
    "# Load data as DF\n",
    "df = CreateDfForModel(ft_wld=True)\n",
    "\n",
    "# team names\n",
    "teams = list(set(df.team_home))\n",
    "teams.sort()\n",
    "\n",
    "[SingleTeamAccuracy(df, team) for team in teams]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class LOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate Accuracy\n",
    "# Log & SVM, cv = 18\n",
    "def ModelAccuracy(X, y, penalty='l2', multi_class='ovr', log_variables=False):\n",
    "    # Set Models\n",
    "    model_log = LogisticRegression(penalty=penalty, multi_class=multi_class)\n",
    "\n",
    "    # Fit to models\n",
    "    model_log = model_log.fit(X, y)\n",
    "\n",
    "    # Cross Validation\n",
    "    scores_log = cross_val_score(model_log, X, y, scoring='accuracy', cv=18)\n",
    "\n",
    "    # Accuracy scores\n",
    "    print(\"--------------------------\\n\")\n",
    "    print(\"[Log]: \\t%.3f (cv: %.3f)\" % (model_log.score(X, y), scores_log.mean()))\n",
    "\n",
    "\n",
    "    # Variable Scores\n",
    "    if log_variables:\n",
    "        dfVars = pd.DataFrame()\n",
    "        dfVars['var'] = X.columns\n",
    "        dfVars['score'] = np.transpose(model_log.coef_)\n",
    "        print(\"\\n\", dfVars)\n",
    "    \n",
    "    return model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = CreateDfForModel(ft_wld=True)\n",
    "\n",
    "# Create X, y for model\n",
    "y, X = dmatrices(\n",
    "    'result ~ \\\n",
    "    anger_home + fear_home + disgust_home + sadness_home + \\\n",
    "    surprise_home + trust_home + joy_home + anticipation_home + \\\n",
    "    anger_away + fear_away + disgust_away + sadness_away + \\\n",
    "    surprise_away + trust_away + joy_away + anticipation_away + \\\n",
    "    pos_home + neg_home + pos_away + neg_away + \\\n",
    "    diff_anger + diff_fear + diff_disgust + diff_sadness + diff_surprise + \\\n",
    "    diff_trust + diff_joy + diff_anticipation + diff_pos + diff_neg',\n",
    "    df, return_type=\"dataframe\")\n",
    "y = np.ravel(y)\n",
    "\n",
    "\n",
    "# prediction reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    76\n",
      "0    52\n",
      "2    49\n",
      "Name: result, dtype: int64\n",
      "1    0.429379\n",
      "0    0.293785\n",
      "2    0.276836\n",
      "Name: result, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = CreateDfForModel(ft_wld=True)\n",
    "\n",
    "# Results\n",
    "# 1: Win, 2:Lose, 3:Draw\n",
    "print(df[\"result\"].value_counts())\n",
    "print(df[\"result\"].value_counts() / df['result'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "# WL, WD, LD\n",
    "dfBin = df[(df.result != 2)].copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 2. Train Classifier\n",
    "\n",
    "# Create X, y for model\n",
    "y, X = dmatrices(\n",
    "    'result ~ \\\n",
    "    anger_home + fear_home + disgust_home + sadness_home + \\\n",
    "    surprise_home + trust_home + joy_home + anticipation_home + \\\n",
    "    anger_away + fear_away + disgust_away + sadness_away + \\\n",
    "    surprise_away + trust_away + joy_away + anticipation_away + \\\n",
    "    pos_home + neg_home + pos_away + neg_away + \\\n",
    "    diff_anger + diff_fear + diff_disgust + diff_sadness + diff_surprise + \\\n",
    "    diff_trust + diff_joy + diff_anticipation + diff_pos + diff_neg',\n",
    "    dfBin, return_type=\"dataframe\")\n",
    "y = np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 18 folds for each of 3 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.755\n",
      "Best parameters set:\n",
      "\tclf__C: 1\n",
      "------------------------------\n",
      "TEST:\n",
      "\n",
      "\n",
      "\n",
      "Accuracy: 0.615384615385\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 2  8]\n",
      " [ 2 14]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.20      0.29        10\n",
      "        1.0       0.64      0.88      0.74        16\n",
      "\n",
      "avg / total       0.58      0.62      0.56        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# =============================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "\n",
    "# Pipelines\n",
    "pipeline = Pipeline([\n",
    "        ('clf', LogisticRegression(penalty='l2'))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Hyper Parameters\n",
    "parameters = {\n",
    "    'clf__C': (0.1, 1, 10),\n",
    "}\n",
    "\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    parameters,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring='accuracy',\n",
    "    cv=18\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# =============================================================\n",
    "\n",
    "# Computing\n",
    "# grid_search.fit(X_train, y_train)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best score: %0.3f' % grid_search.best_score_)\n",
    "print('Best parameters set:')\n",
    "\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    \n",
    "\n",
    "# =============================================================\n",
    "# =============================================================\n",
    "\n",
    "predictions = grid_search.predict(X_test)\n",
    "print(\"------------------------------\")\n",
    "print(\"TEST:\\n\")\n",
    "print('\\n\\nAccuracy:', metrics.accuracy_score(y_test, predictions))\n",
    "print('\\n\\nConfusion Matrix:\\n', metrics.confusion_matrix(y_test, predictions))\n",
    "print('\\n\\nClassification Report:\\n', metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win Lose Model => Draw Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.442713419434 0.557286580566\n"
     ]
    }
   ],
   "source": [
    "dfDraw = df[df.result == 2].copy().reset_index(drop=True)\n",
    "\n",
    "# 2. Train Classifier\n",
    "\n",
    "# Create X, y for model\n",
    "y_draw, X_draw = dmatrices(\n",
    "    'result ~ \\\n",
    "    anger_home + fear_home + disgust_home + sadness_home + \\\n",
    "    surprise_home + trust_home + joy_home + anticipation_home + \\\n",
    "    anger_away + fear_away + disgust_away + sadness_away + \\\n",
    "    surprise_away + trust_away + joy_away + anticipation_away + \\\n",
    "    pos_home + neg_home + pos_away + neg_away + \\\n",
    "    diff_anger + diff_fear + diff_disgust + diff_sadness + diff_surprise + \\\n",
    "    diff_trust + diff_joy + diff_anticipation + diff_pos + diff_neg',\n",
    "    dfDraw, return_type=\"dataframe\")\n",
    "y_draw = np.ravel(y_draw)\n",
    "\n",
    "\n",
    "predictions_draw = grid_search.predict_proba(X_draw)\n",
    "\n",
    "pre_0 = np.array([item[0] for item in predictions_draw])\n",
    "pre_1 = np.array([item[1] for item in predictions_draw])\n",
    "\n",
    "print(pre_0.mean(), pre_1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40732972387 0.59267027613\n"
     ]
    }
   ],
   "source": [
    "y_wl, X_wl = dmatrices(\n",
    "    'result ~ \\\n",
    "    anger_home + fear_home + disgust_home + sadness_home + \\\n",
    "    surprise_home + trust_home + joy_home + anticipation_home + \\\n",
    "    anger_away + fear_away + disgust_away + sadness_away + \\\n",
    "    surprise_away + trust_away + joy_away + anticipation_away + \\\n",
    "    pos_home + neg_home + pos_away + neg_away + \\\n",
    "    diff_anger + diff_fear + diff_disgust + diff_sadness + diff_surprise + \\\n",
    "    diff_trust + diff_joy + diff_anticipation + diff_pos + diff_neg',\n",
    "    dfBin, return_type=\"dataframe\")\n",
    "y_wl = np.ravel(y_wl)\n",
    "\n",
    "\n",
    "predictions_wl = grid_search.predict_proba(X_wl)\n",
    "\n",
    "pre_0 = np.array([item[0] for item in predictions_wl])\n",
    "pre_1 = np.array([item[1] for item in predictions_wl])\n",
    "\n",
    "print(pre_0.mean(), pre_1.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Global Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import datetime\n",
    "from time import gmtime, strftime\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "\n",
    "# Scikit-Learn imports\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# Local Imports\n",
    "path = str(os.path.expanduser('~')) + '/git/predictEPL/config'\n",
    "sys.path.append(path)\n",
    "import paths\n",
    "\n",
    "sys.path.append(paths.UTILS)\n",
    "import useful_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read Data: all_game_emolex_counted\n",
    "def ReadEmoleDf():\n",
    "#     df = useful_methods.csv_dic_df(paths.DATA_HOME + \"EPL/all_game_emolex_counted.csv\")\n",
    "    df = useful_methods.csv_dic_df(paths.DATA_HOME + \"EPL/all_game_emolex_counted_nonretweet.csv\")\n",
    "\n",
    "\n",
    "    # Manipulations\n",
    "\n",
    "    # 'home_win': 1, 'away_win': 0, 'draw': 2\n",
    "    def Labeling(goal_diff):\n",
    "        if goal_diff > 0:\n",
    "            return 1\n",
    "        elif goal_diff < 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "    df.score_ft_home = [int(score_ft_home) for score_ft_home in df.score_ft_home]\n",
    "    df.score_ft_away = [int(score_ft_away) for score_ft_away in df.score_ft_away]\n",
    "\n",
    "    df.pn_home = [np.array([float(pn) for pn in pn_home[1:-1].split(',')]) for pn_home in list(df.pn_home)]\n",
    "    df.pn_away = [np.array([float(pn) for pn in pn_away[1:-1].split(',')]) for pn_away in list(df.pn_away)]\n",
    "\n",
    "    df.emolex_home = [np.array([float(emo) for emo in emolex_home[1:-1].split(',')]) for emolex_home in list(df.emolex_home)]\n",
    "    df.emolex_away = [np.array([float(emo) for emo in emolex_away[1:-1].split(',')]) for emolex_away in list(df.emolex_away)]\n",
    "\n",
    "    df['goal_diff'] = df.score_ft_home - df.score_ft_away\n",
    "    df['result'] = [Labeling(goal_diff) for goal_diff in df.goal_diff]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create df for models.\n",
    "def CreateDfModel(draw=False):\n",
    "    df = ReadEmoleDf()\n",
    "    \n",
    "    if not draw:\n",
    "        df = df[df.result != 2].copy().reset_index(drop=True)\n",
    "    \n",
    "    dta = pd.DataFrame()\n",
    "    \n",
    "    # Teams\n",
    "    dta['team_home'] = df.home_team\n",
    "    dta['team_away'] = df.away_team\n",
    "\n",
    "    # POS, NEG\n",
    "    dta['pos_home'] = [pn_home[0] / sum(pn_home)  for pn_home in df.pn_home]\n",
    "    dta['neg_home'] = [pn_home[1] / sum(pn_home)  for pn_home in df.pn_home]\n",
    "\n",
    "    dta['pos_away'] = [pn_away[0] / sum(pn_away)  for pn_away in df.pn_away]\n",
    "    dta['neg_away'] = [pn_away[1] / sum(pn_away)  for pn_away in df.pn_away]\n",
    "    \n",
    "    dta['diff_pos'] = dta['pos_home'] - dta['pos_away']\n",
    "    \n",
    "    # HF scores\n",
    "    dta['score_ht_home'] = [int(score_ht_home) for score_ht_home in df.score_ht_home]\n",
    "    dta['score_ht_away'] = [int(score_ht_away) for score_ht_away in df.score_ht_away]\n",
    "\n",
    "    # Emolex 8\n",
    "    dta['anger_home'] = [emolex[0] / sum(emolex) for emolex in df.emolex_home]\n",
    "    dta['fear_home'] = [emolex[1] / sum(emolex) for emolex in df.emolex_home]\n",
    "    dta['disgust_home'] = [emolex[2] / sum(emolex) for emolex in df.emolex_home]\n",
    "    dta['sadness_home'] = [emolex[3] / sum(emolex)  for emolex in df.emolex_home]\n",
    "    dta['surprise_home'] = [emolex[4] / sum(emolex)  for emolex in df.emolex_home]\n",
    "    dta['trust_home'] = [emolex[5] / sum(emolex)  for emolex in df.emolex_home]\n",
    "    dta['joy_home'] = [emolex[6] / sum(emolex)  for emolex in df.emolex_home]\n",
    "    dta['anticipation_home'] = [emolex[7] / sum(emolex)  for emolex in df.emolex_home]\n",
    "\n",
    "    dta['anger_away'] = [emolex[0] / sum(emolex)  for emolex in df.emolex_away]\n",
    "    dta['fear_away'] = [emolex[1] / sum(emolex)  for emolex in df.emolex_away]\n",
    "    dta['disgust_away'] = [emolex[2] / sum(emolex)  for emolex in df.emolex_away]\n",
    "    dta['sadness_away'] = [emolex[3] / sum(emolex)  for emolex in df.emolex_away]\n",
    "    dta['surprise_away'] = [emolex[4] / sum(emolex)  for emolex in df.emolex_away]\n",
    "    dta['trust_away'] = [emolex[5] / sum(emolex)  for emolex in df.emolex_away]\n",
    "    dta['joy_away'] = [emolex[6] / sum(emolex)  for emolex in df.emolex_away]\n",
    "    dta['anticipation_away'] = [emolex[7] / sum(emolex)  for emolex in df.emolex_away]\n",
    "\n",
    "    # 'home_win': 1, 'away_win': 0, 'draw': 2\n",
    "    dta['result'] = df.result\n",
    "    \n",
    "    return dta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X: df, y: list\n",
    "def CreateXy(df, team_name=False, emolex=False):\n",
    "    if team_name and emolex:\n",
    "        y, X = dmatrices('result ~ \\\n",
    "            pos_home + neg_home + pos_away + neg_away + \\\n",
    "            score_ht_home + score_ht_away + \\\n",
    "            diff_pos + \\\n",
    "            anger_home + fear_home + disgust_home + sadness_home + \\\n",
    "            surprise_home + trust_home + joy_home + anticipation_home + \\\n",
    "            anger_away + fear_away + disgust_away + sadness_away + \\\n",
    "            surprise_away + trust_away + joy_away + anticipation_away + \\\n",
    "            C(team_home) + C(team_away)',\n",
    "            df, return_type=\"dataframe\")\n",
    "    elif team_name:\n",
    "        y, X = dmatrices('result ~ \\\n",
    "            pos_home + neg_home + pos_away + neg_away + \\\n",
    "            score_ht_home + score_ht_away + \\\n",
    "            diff_pos + \\\n",
    "            C(team_home) + C(team_away)',\n",
    "            df, return_type=\"dataframe\")\n",
    "    elif emolex:\n",
    "        y, X = dmatrices('result ~ \\\n",
    "            pos_home + neg_home + pos_away + neg_away + \\\n",
    "            score_ht_home + score_ht_away + \\\n",
    "            diff_pos + \\\n",
    "            anger_home + fear_home + disgust_home + sadness_home + \\\n",
    "            surprise_home + trust_home + joy_home + anticipation_home + \\\n",
    "            anger_away + fear_away + disgust_away + sadness_away + \\\n",
    "            surprise_away + trust_away + joy_away + anticipation_away',\n",
    "            df, return_type=\"dataframe\")\n",
    "    else:\n",
    "        y, X = dmatrices('result ~ \\\n",
    "            pos_home + neg_home + pos_away + neg_away + \\\n",
    "            score_ht_home + score_ht_away + \\\n",
    "            diff_pos',\n",
    "            df, return_type=\"dataframe\")\n",
    "\n",
    "    # flatten y into a 1-D array\n",
    "    y = np.ravel(y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Manipulation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print Training Parameters\n",
    "def DetecterParams(detecter, title=\"\", all_tunes=True):\n",
    "    print(\"\\n\\n### PARAMS ################################\\n\")\n",
    "\n",
    "    if all_tunes:\n",
    "        print(\"[All Params Results]:\\n\")\n",
    "        pprint(detecter.grid_scores_)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    print(\"[%s Detecter Params]: \\n\" % title)\n",
    "    print(\"Best Score: \", detecter.best_score_)\n",
    "    print(\"Best Params: \", detecter.best_params_)\n",
    "\n",
    "\n",
    "# Print Test Prediction\n",
    "def DetecterMetrics(features, labels, detecter, title=\"\"):\n",
    "    predictions = detecter.predict(features)\n",
    "    print(\"\\n\\n### METRICS ###############################\\n\")\n",
    "\n",
    "    print(\"[%s Results]: \\n\" % title)\n",
    "    print(metrics.classification_report(labels, predictions))\n",
    "    print('[Accuracy]: ', metrics.accuracy_score(labels, predictions))\n",
    "\n",
    "\n",
    "# Receiver Operating Characteristic = ROC curve\n",
    "# Visualizes a classifier's performance\n",
    "# for all values of the discrimination threshold. \n",
    "# fall out: F = FP / (TN + FP)\n",
    "# AUC (area under the curve)\n",
    "def PlotRocAuc(features, labels, detecter, title=\"\"):\n",
    "    # predict features\n",
    "    predictions = detecter.predict_proba(features)\n",
    "    \n",
    "    # calculate Fall Out & Recall\n",
    "    false_positive_rate, recall, thresholds = metrics.roc_curve(\n",
    "        labels, predictions[:, 1])\n",
    "\n",
    "    # ROC AUC\n",
    "    roc_auc = metrics.auc(false_positive_rate, recall)\n",
    "\n",
    "    # Plot\n",
    "    plt.title('Receiver Operating Characteristic: ' + title)\n",
    "    plt.plot(false_positive_rate, recall, 'b', label='AUC = %0.2f' % roc_auc)\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Fall-out')\n",
    "    plt.show()\n",
    "\n",
    "# ****************************************************************************\n",
    "# ****************************************************************************\n",
    "\n",
    "# Define Logistic Recression\n",
    "def Log(y_train, n_folds=10):\n",
    "    # putting the steps explicitly into Pipeline\n",
    "    pipeline_log = Pipeline([\n",
    "            ('clf', LogisticRegression())\n",
    "        ])\n",
    "\n",
    "    # tunning parameters\n",
    "    params_log = {\n",
    "        'clf__C': (1, 10, 100),\n",
    "#         'clf__multi_class': ('ovr', 'multinomial'),\n",
    "#         'clf__penalty': ('l1', 'l2')\n",
    "    }\n",
    "\n",
    "    # grid search\n",
    "    grid_log = GridSearchCV(\n",
    "        pipeline_log,        # pipeline from above\n",
    "        params_log,          # parameters to tune via cross validation\n",
    "        refit=True,          # fit using all available data at the end, on the best found param combination\n",
    "        n_jobs=-1,           # number of cores to use for parallelization; -1 for \"all cores\"\n",
    "        scoring='accuracy',  # what score are we optimizing?\n",
    "        cv=StratifiedKFold(y_train, n_folds=n_folds),  # what type of cross validation to use\n",
    "#         cv=n_folds\n",
    "    )\n",
    "\n",
    "    return grid_log\n",
    "\n",
    "\n",
    "# ****************************************************************************\n",
    "# ****************************************************************************\n",
    "\n",
    "# Define Support Vector Machine\n",
    "# return: gridsearch SVM\n",
    "def SVM(y_train, n_folds=10):\n",
    "    # putting the steps explicitly into Pipeline\n",
    "    pipeline_svm = Pipeline([\n",
    "            # train on vectors with classifier\n",
    "            ('clf', SVC())\n",
    "        ])\n",
    "\n",
    "    # tunning parameters\n",
    "    params_svm = {\n",
    "        'clf__kernel': ('linear', 'poly', 'rbf'),\n",
    "        'clf__gamma': (0.00001, 0.0001, 00.1),\n",
    "        'clf__C': (1, 10, 100),\n",
    "    }\n",
    "\n",
    "    # grid search\n",
    "    grid_svm = GridSearchCV(\n",
    "        pipeline_svm,        # pipeline from above\n",
    "        params_svm,          # parameters to tune via cross validation\n",
    "        refit=True,          # fit using all available data at the end, on the best found param combination\n",
    "        n_jobs=-1,           # number of cores to use for parallelization; -1 for \"all cores\"\n",
    "        scoring='accuracy',  # what score are we optimizing?\n",
    "        cv=StratifiedKFold(y_train, n_folds=n_folds),  # what type of cross validation to use\n",
    "    )\n",
    "\n",
    "    return grid_svm\n",
    "\n",
    "\n",
    "\n",
    "# ****************************************************************************\n",
    "# ****************************************************************************\n",
    "\n",
    "# Define Decision Trees\n",
    "def DT(y_train, n_folds=10):\n",
    "    # putting the steps explicitly into Pipeline\n",
    "    pipeline_dt = Pipeline([\n",
    "            # train on vectors with classifier\n",
    "            ('clf', RandomForestClassifier(criterion='entropy'))\n",
    "        ])\n",
    "\n",
    "    # tunning parameters\n",
    "    params_dt = {\n",
    "        'clf__n_estimators': (5, 10, 20, 50),\n",
    "        'clf__max_depth': (50, 150, 250),\n",
    "        'clf__min_samples_split': (1, 2, 3),\n",
    "        'clf__min_samples_leaf': (1, 2, 3)\n",
    "    }\n",
    "\n",
    "    # grid search\n",
    "    grid_dt = GridSearchCV(\n",
    "        pipeline_dt,        # pipeline from above\n",
    "        params_dt,          # parameters to tune via cross validation\n",
    "        refit=True,          # fit using all available data at the end, on the best found param combination\n",
    "        n_jobs=-1,           # number of cores to use for parallelization; -1 for \"all cores\"\n",
    "        scoring='accuracy',  # what score are we optimizing?\n",
    "        cv=StratifiedKFold(y_train, n_folds=n_folds),  # what type of cross validation to use\n",
    "    )\n",
    "\n",
    "    return grid_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ModelTrain(X, y, model, n_folds=10, test_size=0.2):\n",
    "    # ***************************************************\n",
    "    # [Step 2]: Data Split(train=0.8, test=0.2)\n",
    "    # ***************************************************\n",
    "\n",
    "    date_now = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()).replace(\" \", \"_\")\n",
    "\n",
    "    # Split data Train and Test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=test_size)\n",
    "\n",
    "#     print(\n",
    "#         \"\\n\\n### DATA ##################################\\n\",\n",
    "#         \"\\n\\tTrain data: \\t\", len(X_train),\n",
    "#         \"\\n\\tTest data: \\t\", len(X_test),\n",
    "#         \"\\n\\tAll data: \\t\", len(y_train) + len(y_test)\n",
    "#     )\n",
    "\n",
    "    # ***************************************************\n",
    "    # [Step 3]: Define Classifier\n",
    "    # ***************************************************\n",
    "    \n",
    "    if model == 'LOG':\n",
    "        grid_search = Log(y_train, n_folds)\n",
    "    elif model == 'SVM':\n",
    "        grid_search = SVM(y_train, n_folds)\n",
    "    elif model == 'DT':\n",
    "        grid_search = DT(y_train, n_folds)\n",
    "\n",
    "    # ***************************************************\n",
    "    # [Step 4]: Compute Classifier\n",
    "    # ***************************************************\n",
    "\n",
    "    start_time = time()\n",
    "\n",
    "    # fitting training sets to classifier\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # ***************************************************\n",
    "    # [Step 4]: Print Classifier Details\n",
    "    # ***************************************************\n",
    "\n",
    "    # print trained parameters\n",
    "    DetecterParams(grid_search, title=model, all_tunes=False)\n",
    "\n",
    "    # print computed time\n",
    "#     print(\"\\n\\n### COMPUTED TIME #########################\\n\")\n",
    "#     taken_time = time() - start_time\n",
    "#     print(\"[Started Time]: \", date_now)\n",
    "#     print(\"\\n[Taken Time]: \", str(datetime.timedelta(seconds=taken_time)))\n",
    "\n",
    "    # print classifier test results\n",
    "#     DetecterMetrics(X_train, y_train, grid_search, title=model + \": Train\")\n",
    "#     DetecterMetrics(X_test, y_test, grid_search, title=model + \": Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### PARAMS ################################\n",
      "\n",
      "[LOG Detecter Params]: \n",
      "\n",
      "Best Score:  0.513333333333\n",
      "Best Params:  {'clf__C': 1}\n",
      "\n",
      "\n",
      "### PARAMS ################################\n",
      "\n",
      "[SVM Detecter Params]: \n",
      "\n",
      "Best Score:  0.613333333333\n",
      "Best Params:  {'clf__kernel': 'rbf', 'clf__gamma': 0.1, 'clf__C': 1}\n"
     ]
    }
   ],
   "source": [
    "# ***************************************************\n",
    "# [Step 2]: Data Prepare\n",
    "# ***************************************************\n",
    "\n",
    "\n",
    "# Create DFs for models\n",
    "# WL: win, lose; WLD: win, lose, draw\n",
    "dfWL = CreateDfModel()\n",
    "dfWLD = CreateDfModel(draw=True)\n",
    "\n",
    "# 'home_win': 1, 'away_win': 0, 'draw': 2\n",
    "dfWLD.groupby('result').mean()\n",
    "\n",
    "# Prepare Data for Logistic Regression\n",
    "X, y = CreateXy(dfWLD, team_name=False, emolex=True)\n",
    "\n",
    "# Train Model\n",
    "ModelTrain(X, y, model='LOG', n_folds=30, test_size=0.1)\n",
    "ModelTrain(X, y, model='SVM', n_folds=30, test_size=0.1)\n",
    "# ModelTrain(X, y, model='DT', n_folds=30, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PlotRocAuc(X_train, y_train, grid_search, title=\"Log Train\")\n",
    "PlotRocAuc(X_test, y_test, grid_search, title=\"Log Test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

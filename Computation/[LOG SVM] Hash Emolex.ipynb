{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Global Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import datetime\n",
    "from time import gmtime, strftime\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "\n",
    "# Scikit-Learn imports\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# Local Imports\n",
    "path = str(os.path.expanduser('~')) + '/git/predictEPL/config'\n",
    "sys.path.append(path)\n",
    "import paths\n",
    "\n",
    "sys.path.append(paths.UTILS)\n",
    "import useful_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definings\n",
    "RESULT_FILE_NAME = \"log_hash_all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ReadHashDf():\n",
    "    # Read game_infos as df\n",
    "    dfGameInfo = useful_methods.csv_dic_df(paths.READ_PATH_GAME_INFO + 'game_infos.csv')\n",
    "    dfGameInfo = useful_methods.DropNanGames(dfGameInfo).copy().reset_index(drop=True)\n",
    "    dfGameInfo.GW = [int(gw) for gw in dfGameInfo.GW]\n",
    "    dfGameInfo = dfGameInfo.sort_values(['GW', 'away_team'], ascending=[True, True]).copy().reset_index(drop=True)\n",
    "\n",
    "    # Read Hash Emolex Model result\n",
    "    df = useful_methods.csv_dic_df(paths.READ_PATH_RESULTS + RESULT_FILE_NAME)\n",
    "    df.GW = [int(gw) for gw in df.GW]\n",
    "    df = df.sort_values(['GW', 'away_team'], ascending=[True, True]).copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # Combine 2 dfs\n",
    "    df['score_ht_away'] = [int(item) for item in dfGameInfo.score_ht_away]\n",
    "    df['score_ht_home'] = [int(item) for item in dfGameInfo.score_ht_home]\n",
    "    df['score_ft_away'] = [int(item) for item in dfGameInfo.score_ft_away]\n",
    "    df['score_ft_home'] = [int(item) for item in dfGameInfo.score_ft_home]\n",
    "\n",
    "    df['pn_away_neg'] = [float(item) for item in df.pn_away_neg]\n",
    "    df['pn_away_pos'] = [float(item) for item in df.pn_away_pos]\n",
    "    df['pn_home_neg'] = [float(item) for item in df.pn_home_neg]\n",
    "    df['pn_home_pos'] = [float(item) for item in df.pn_home_pos]\n",
    "\n",
    "    # 'home_win': 1, 'away_win': 0, 'draw': 2\n",
    "    def Labeling(goal_diff):\n",
    "        if goal_diff > 0:\n",
    "            return 1\n",
    "        elif goal_diff < 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "    df['goal_diff_ht'] = df.score_ht_home - df.score_ht_away\n",
    "    df['goal_diff_ft'] = df.score_ft_home - df.score_ft_away\n",
    "    df['result'] = [Labeling(item) for item in df.goal_diff_ft]\n",
    "\n",
    "\n",
    "    # **********************************************\n",
    "    # Add previous 4 games points sum\n",
    "    dfBe4GameSum = useful_methods.csv_dic_df(paths.DATA_HOME + \"EPL/info_before_4game_sum.csv\")\n",
    "\n",
    "    team_homes = list(df.home_team)\n",
    "    team_aways = list(df.away_team)\n",
    "    GWs = [int(gw) for gw in df.GW]\n",
    "\n",
    "    be_4game_sum_home = []\n",
    "    be_4game_sum_away = []\n",
    "\n",
    "    for index in range(len(GWs)):\n",
    "        team_home = team_homes[index]\n",
    "        team_away = team_aways[index]\n",
    "        gw = GWs[index]\n",
    "\n",
    "        be_4game_sum_home.append(int(dfBe4GameSum[dfBe4GameSum.team == team_home][str(gw)]))\n",
    "        be_4game_sum_away.append(int(dfBe4GameSum[dfBe4GameSum.team == team_away][str(gw)]))\n",
    "\n",
    "    df['be_4game_sum_away'] = be_4game_sum_away\n",
    "    df['be_4game_sum_home'] = be_4game_sum_home    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create df for models.\n",
    "def CreateDfForModel(ht_draw=False, ft_wld=False):\n",
    "    df = ReadHashDf()\n",
    "        \n",
    "    # only for Win or Lose\n",
    "    if not ft_wld:\n",
    "        df = df[df.result != 2].copy().reset_index(drop=True)\n",
    "    \n",
    "    # HT: Equal\n",
    "    if ht_draw:\n",
    "        df = df[df.goal_diff_ht == 0].copy().reset_index(drop=True)\n",
    "    \n",
    "    dta = pd.DataFrame()\n",
    "    \n",
    "    # Teams\n",
    "    dta['team_home'] = df.home_team\n",
    "    dta['team_away'] = df.away_team\n",
    "\n",
    "    # POS, NEG scores by percentage %\n",
    "    dta['pn_home_pos'] = df.pn_home_pos / (df.pn_home_pos + df.pn_home_neg)\n",
    "    dta['pn_home_neg'] = df.pn_home_neg / (df.pn_home_pos + df.pn_home_neg)\n",
    "    dta['pn_away_pos'] = df.pn_away_pos / (df.pn_away_pos + df.pn_away_neg)\n",
    "    dta['pn_away_neg'] = df.pn_away_neg / (df.pn_away_pos + df.pn_away_neg)\n",
    "    \n",
    "    dta['pn_diff_pos'] = dta['pn_home_pos'] - dta['pn_away_pos']\n",
    "    \n",
    "    # HF scores\n",
    "    dta['score_ht_home'] = df.score_ht_home\n",
    "    dta['score_ht_away'] = df.score_ht_away\n",
    "    \n",
    "    dta['goal_diff_ht'] = df['goal_diff_ht']\n",
    "\n",
    "    # 'home_win': 1, 'away_win': 0, 'draw': 2\n",
    "    dta['result'] = df.result\n",
    "    \n",
    "    # be_4game_sum\n",
    "    dta['be_4game_sum_home'] = df.be_4game_sum_home / 12.0\n",
    "    dta['be_4game_sum_away'] = df.be_4game_sum_away / 12.0\n",
    "    \n",
    "    return dta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X: df, y: list\n",
    "def CreateXy(df, team_name=False, hash_emolex=True, score_ht=True, be_4game_sum=False):\n",
    "    if team_name and hash_emolex and score_ht and be_4game_sum:\n",
    "        y, X = dmatrices('result ~ \\\n",
    "            be_4game_sum_home + be_4game_sum_away + \\\n",
    "            score_ht_home + score_ht_away + \\\n",
    "            pn_home_pos + pn_home_neg + pn_away_pos + pn_away_neg + \\\n",
    "            pn_diff_pos + \\\n",
    "            C(team_home) + C(team_away)',\n",
    "            df, return_type=\"dataframe\")\n",
    "    elif hash_emolex and score_ht and be_4game_sum:\n",
    "        y, X = dmatrices('result ~ \\\n",
    "            be_4game_sum_home + be_4game_sum_away + \\\n",
    "            score_ht_home + score_ht_away + \\\n",
    "            pn_home_pos + pn_home_neg + pn_away_pos + pn_away_neg + \\\n",
    "            pn_diff_pos',\n",
    "            df, return_type=\"dataframe\")\n",
    "    elif hash_emolex and be_4game_sum:\n",
    "        y, X = dmatrices('result ~ \\\n",
    "            be_4game_sum_home + be_4game_sum_away + \\\n",
    "            pn_home_pos + pn_home_neg + pn_away_pos + pn_away_neg + \\\n",
    "            pn_diff_pos',\n",
    "            df, return_type=\"dataframe\")\n",
    "    elif score_ht and be_4game_sum:\n",
    "        y, X = dmatrices('result ~ \\\n",
    "            score_ht_home + score_ht_away + \\\n",
    "            be_4game_sum_home + be_4game_sum_away',\n",
    "            df, return_type=\"dataframe\")\n",
    "    elif hash_emolex:\n",
    "        y, X = dmatrices('result ~ \\\n",
    "            pn_home_pos + pn_home_neg + pn_away_pos + pn_away_neg + \\\n",
    "            pn_diff_pos',\n",
    "            df, return_type=\"dataframe\")\n",
    "    else:\n",
    "        y, X = dmatrices('result ~ \\\n",
    "            score_ht_home + score_ht_away',\n",
    "            df, return_type=\"dataframe\")\n",
    "        \n",
    "    # flatten y into a 1-D array\n",
    "    y = np.ravel(y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Manipulation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print Training Parameters\n",
    "def DetecterParams(detecter, title=\"\", all_tunes=True):\n",
    "    print(\"\\n\\n### PARAMS ################################\\n\")\n",
    "\n",
    "    if all_tunes:\n",
    "        print(\"[All Params Results]:\\n\")\n",
    "        pprint(detecter.grid_scores_)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    print(\"[%s Detecter Params]: \\n\" % title)\n",
    "    print(\"Best Score: \", detecter.best_score_)\n",
    "    print(\"Best Params: \", detecter.best_params_)\n",
    "\n",
    "\n",
    "# Print Test Prediction\n",
    "def DetecterMetrics(features, labels, detecter, title=\"\"):\n",
    "    predictions = detecter.predict(features)\n",
    "    print(\"\\n\\n### METRICS ###############################\\n\")\n",
    "\n",
    "    print(\"[%s Results]: \\n\" % title)\n",
    "    print(metrics.classification_report(labels, predictions))\n",
    "    print('[Accuracy]: ', metrics.accuracy_score(labels, predictions))\n",
    "\n",
    "\n",
    "# Receiver Operating Characteristic = ROC curve\n",
    "# Visualizes a classifier's performance\n",
    "# for all values of the discrimination threshold. \n",
    "# fall out: F = FP / (TN + FP)\n",
    "# AUC (area under the curve)\n",
    "def PlotRocAuc(features, labels, detecter, title=\"\"):\n",
    "    # predict features\n",
    "    predictions = detecter.predict_proba(features)\n",
    "    \n",
    "    # calculate Fall Out & Recall\n",
    "    false_positive_rate, recall, thresholds = metrics.roc_curve(\n",
    "        labels, predictions[:, 1])\n",
    "\n",
    "    # ROC AUC\n",
    "    roc_auc = metrics.auc(false_positive_rate, recall)\n",
    "\n",
    "    # Plot\n",
    "    plt.title('Receiver Operating Characteristic: ' + title)\n",
    "    plt.plot(false_positive_rate, recall, 'b', label='AUC = %0.2f' % roc_auc)\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Fall-out')\n",
    "    plt.show()\n",
    "\n",
    "# ****************************************************************************\n",
    "# ****************************************************************************\n",
    "\n",
    "# Define Logistic Recression\n",
    "def Log(y_train, n_folds=10):\n",
    "    # putting the steps explicitly into Pipeline\n",
    "    pipeline_log = Pipeline([\n",
    "            ('clf', LogisticRegression())\n",
    "        ])\n",
    "\n",
    "    # tunning parameters\n",
    "    params_log = {\n",
    "        'clf__C': (1, 10, 100),\n",
    "#         'clf__multi_class': ('ovr', 'multinomial'),\n",
    "#         'clf__penalty': ('l1', 'l2')\n",
    "    }\n",
    "\n",
    "    # grid search\n",
    "    grid_log = GridSearchCV(\n",
    "        pipeline_log,        # pipeline from above\n",
    "        params_log,          # parameters to tune via cross validation\n",
    "        refit=True,          # fit using all available data at the end, on the best found param combination\n",
    "        n_jobs=-1,           # number of cores to use for parallelization; -1 for \"all cores\"\n",
    "        scoring='accuracy',  # what score are we optimizing?\n",
    "        cv=StratifiedKFold(y_train, n_folds=n_folds),  # what type of cross validation to use\n",
    "#         cv=n_folds\n",
    "    )\n",
    "\n",
    "    return grid_log\n",
    "\n",
    "\n",
    "# ****************************************************************************\n",
    "# ****************************************************************************\n",
    "\n",
    "# Define Support Vector Machine\n",
    "# return: gridsearch SVM\n",
    "def SVM(y_train, n_folds=10):\n",
    "    # putting the steps explicitly into Pipeline\n",
    "    pipeline_svm = Pipeline([\n",
    "            # train on vectors with classifier\n",
    "            ('clf', SVC())\n",
    "        ])\n",
    "\n",
    "    # tunning parameters\n",
    "    params_svm = {\n",
    "        'clf__kernel': ('linear', 'poly', 'rbf'),\n",
    "        'clf__gamma': (0.00001, 0.0001, 00.1),\n",
    "        'clf__C': (1, 10, 100),\n",
    "    }\n",
    "\n",
    "    # grid search\n",
    "    grid_svm = GridSearchCV(\n",
    "        pipeline_svm,        # pipeline from above\n",
    "        params_svm,          # parameters to tune via cross validation\n",
    "        refit=True,          # fit using all available data at the end, on the best found param combination\n",
    "        n_jobs=-1,           # number of cores to use for parallelization; -1 for \"all cores\"\n",
    "        scoring='accuracy',  # what score are we optimizing?\n",
    "        cv=StratifiedKFold(y_train, n_folds=n_folds),  # what type of cross validation to use\n",
    "    )\n",
    "\n",
    "    return grid_svm\n",
    "\n",
    "\n",
    "\n",
    "# ****************************************************************************\n",
    "# ****************************************************************************\n",
    "\n",
    "# Define Decision Trees\n",
    "def DT(y_train, n_folds=10):\n",
    "    # putting the steps explicitly into Pipeline\n",
    "    pipeline_dt = Pipeline([\n",
    "            # train on vectors with classifier\n",
    "            ('clf', RandomForestClassifier(criterion='entropy'))\n",
    "        ])\n",
    "\n",
    "    # tunning parameters\n",
    "    params_dt = {\n",
    "        'clf__n_estimators': (5, 10, 20, 50),\n",
    "        'clf__max_depth': (50, 150, 250),\n",
    "        'clf__min_samples_split': (1, 2, 3),\n",
    "        'clf__min_samples_leaf': (1, 2, 3)\n",
    "    }\n",
    "\n",
    "    # grid search\n",
    "    grid_dt = GridSearchCV(\n",
    "        pipeline_dt,        # pipeline from above\n",
    "        params_dt,          # parameters to tune via cross validation\n",
    "        refit=True,          # fit using all available data at the end, on the best found param combination\n",
    "        n_jobs=-1,           # number of cores to use for parallelization; -1 for \"all cores\"\n",
    "        scoring='accuracy',  # what score are we optimizing?\n",
    "        cv=StratifiedKFold(y_train, n_folds=n_folds),  # what type of cross validation to use\n",
    "    )\n",
    "\n",
    "    return grid_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ModelTrain(X, y, model, n_folds=10, test_size=0.2,\n",
    "               print_data_num=False, print_detecter_params=False):\n",
    "    # ***************************************************\n",
    "    # [Step 2]: Data Split(train=0.8, test=0.2)\n",
    "    # ***************************************************\n",
    "\n",
    "    date_now = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()).replace(\" \", \"_\")\n",
    "\n",
    "    # Split data Train and Test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    if print_data_num:\n",
    "        print(\n",
    "            \"\\n\\n### DATA ##################################\\n\",\n",
    "            \"\\n\\tTrain data: \\t\", len(X_train),\n",
    "            \"\\n\\tTest data: \\t\", len(X_test),\n",
    "            \"\\n\\tAll data: \\t\", len(y_train) + len(y_test)\n",
    "        )\n",
    "\n",
    "    # ***************************************************\n",
    "    # [Step 3]: Define Classifier\n",
    "    # ***************************************************\n",
    "    \n",
    "    if model == 'LOG':\n",
    "        grid_search = Log(y_train, n_folds)\n",
    "    elif model == 'SVM':\n",
    "        grid_search = SVM(y_train, n_folds)\n",
    "    elif model == 'DT':\n",
    "        grid_search = DT(y_train, n_folds)\n",
    "\n",
    "    # ***************************************************\n",
    "    # [Step 4]: Compute Classifier\n",
    "    # ***************************************************\n",
    "\n",
    "    start_time = time()\n",
    "\n",
    "    # fitting training sets to classifier\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # ***************************************************\n",
    "    # [Step 4]: Print Classifier Details\n",
    "    # ***************************************************\n",
    "\n",
    "    # print trained parameters\n",
    "    if print_detecter_params:\n",
    "        DetecterParams(grid_search, title=model, all_tunes=False)\n",
    "\n",
    "    # print classifier test results\n",
    "#     DetecterMetrics(X_train, y_train, grid_search, title=model + \": Train\")\n",
    "#     DetecterMetrics(X_test, y_test, grid_search, title=model + \": Test\")\n",
    "\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# [Step 2]: Data Prepare\n",
    "# ***************************************************\n",
    "\n",
    "\n",
    "# Create DFs for models\n",
    "# WL: win, lose; WLD: win, lose, draw\n",
    "dfWL = CreateDfModel(draw=False, ht_draw=False)\n",
    "dfWLD = CreateDfModel(draw=True, ht_draw=False)\n",
    "\n",
    "# 'home_win': 1, 'away_win': 0, 'draw': 2\n",
    "dfWLD.groupby('result').mean()\n",
    "\n",
    "# Prepare Data for Logistic Regression\n",
    "X, y = CreateXy(dfWL, team_name=False, hash_emolex=True, score_ht=True, be_4game_sum=True)\n",
    "\n",
    "# Train Model\n",
    "log_wl = ModelTrain(X, y, model='LOG', n_folds=18, test_size=0.0)\n",
    "svm_wl = ModelTrain(X, y, model='SVM', n_folds=18, test_size=0.0)\n",
    "\n",
    "\n",
    "# Prepare Data for Logistic Regression\n",
    "X, y = CreateXy(dfWLD, team_name=False, hash_emolex=True, score_ht=True, be_4game_sum=True)\n",
    "\n",
    "# Train Model\n",
    "log_wld = ModelTrain(X, y, model='LOG', n_folds=10, test_size=0.0)\n",
    "svm_wld = ModelTrain(X, y, model='SVM', n_folds=10, test_size=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varible Scores & CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ModelScoresWL(df, team_name, hash_emolex, score_ht, be_4game_sum, variable_scores=False):\n",
    "    # instantiate a logistic regression model, and fit with X and y\n",
    "    X, y = CreateXy(df, team_name, hash_emolex, score_ht, be_4game_sum)\n",
    "\n",
    "    # Set Models\n",
    "    model_log = LogisticRegression()\n",
    "    model_svc = SVC()\n",
    "\n",
    "    # Fit to models\n",
    "    model_log = model_log.fit(X, y)\n",
    "    model_svc = model_svc.fit(X, y)\n",
    "\n",
    "    # Cross Validation\n",
    "    scores_log = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=18)\n",
    "    scores_svc = cross_val_score(SVC(), X, y, scoring='accuracy', cv=18)\n",
    "\n",
    "    # Accuracy scores\n",
    "    print(\"--------------------------\\n\")\n",
    "    print(\"[Log]: \\t%.3f (cv: %.3f)\" % (model_log.score(X, y), scores_log.mean()))\n",
    "    print(\"[SVC]: \\t%.3f (cv: %.3f)\" % (model_svc.score(X, y), scores_svc.mean()))\n",
    "    \n",
    "    \n",
    "    if variable_scores:\n",
    "        # Variable Scores\n",
    "        dfVars = pd.DataFrame()\n",
    "        dfVars['var'] = X.columns\n",
    "        dfVars['score'] = np.transpose(model_log.coef_)\n",
    "        print(\"\\n\", dfVars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CreateDfForModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ModelScoresWL(dfWL, team_name=False, hash_emolex=False, score_ht=True, be_4game_sum=False)\n",
    "ModelScoresWL(dfWL, team_name=False, hash_emolex=False, score_ht=True, be_4game_sum=True)\n",
    "ModelScoresWL(dfWL, team_name=False, hash_emolex=True, score_ht=False, be_4game_sum=False)\n",
    "ModelScoresWL(dfWL, team_name=False, hash_emolex=True, score_ht=False, be_4game_sum=True)\n",
    "ModelScoresWL(dfWL, team_name=False, hash_emolex=True, score_ht=True, be_4game_sum=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ModelScoresWLD(df, team_name, hash_emolex, score_ht, be_4game_sum):\n",
    "    # instantiate a logistic regression model, and fit with X and y\n",
    "    X, y = CreateXy(df, team_name, hash_emolex, score_ht, be_4game_sum)\n",
    "\n",
    "    # Set Models\n",
    "    model_log = LogisticRegression()\n",
    "    model_svc = SVC()\n",
    "\n",
    "    # Fit to models\n",
    "    model_log = model_log.fit(X, y)\n",
    "    model_svc = model_svc.fit(X, y)\n",
    "\n",
    "    # Cross Validation\n",
    "    scores_log = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=18)\n",
    "    scores_svc = cross_val_score(SVC(), X, y, scoring='accuracy', cv=18)\n",
    "\n",
    "    # Accuracy scores\n",
    "    print(\"--------------------------\\n\")\n",
    "    print(\"[Log]: \\t%.3f (cv: %.3f)\" % (model_log.score(X, y), scores_log.mean()))\n",
    "    print(\"[SVC]: \\t%.3f (cv: %.3f)\" % (model_svc.score(X, y), scores_svc.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ModelScoresWLD(dfWLD, team_name=False, hash_emolex=False, score_ht=True, be_4game_sum=False)\n",
    "ModelScoresWLD(dfWLD, team_name=False, hash_emolex=False, score_ht=True, be_4game_sum=True)\n",
    "ModelScoresWLD(dfWLD, team_name=False, hash_emolex=True, score_ht=False, be_4game_sum=False)\n",
    "ModelScoresWLD(dfWLD, team_name=False, hash_emolex=True, score_ht=False, be_4game_sum=True)\n",
    "ModelScoresWLD(dfWLD, team_name=False, hash_emolex=True, score_ht=True, be_4game_sum=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
